{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가문항\n",
    "\n",
    "상세기준\n",
    "1. BERT pretrained model을 활용한 KorQuAD 모델이 정상적으로 학습이 진행되었다.\n",
    "    - KorQuAD 모델의 validation accuracy가 안정적으로 증가하였다.\n",
    "\n",
    "2. KorQuAD Inference 결과가 원래의 정답과 비교하여 유사하게 나오는 것을 확인하였다.\n",
    "    - 평가셋에 대해 모델 추론 결과와 실제 정답의 유사성이 확인되었다.\n",
    "3. pretrained model 활용이 효과적임을 실험을 통해 확인하였다.\n",
    "    - pretrained model을 사용하지 않았을 때 대비 학습경과의 차이를 시각화를 통해 확인하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업 경로 폴더 생성\n",
    "# $ mkdir -p ~/aiffel/bert_qna/data\n",
    "# $ mkdir -p ~/aiffel/bert_qna/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for aiffel: "
     ]
    }
   ],
   "source": [
    "# 폰트 설치\n",
    "# ! apt update -qq\n",
    "# ! apt install fonts-nanum* -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\r\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\r\n"
     ]
    }
   ],
   "source": [
    "# pydot을 이용한 모델 시각화를 위한 패키지 설치\n",
    "! apt install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons==0.11.2 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from tensorflow_addons==0.11.2) (2.11.1)\n",
      "Requirement already satisfied: sentencepiece in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (0.1.95)\n",
      "Requirement already satisfied: wordcloud in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from wordcloud) (1.19.2)\n",
      "Requirement already satisfied: matplotlib in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from wordcloud) (3.3.2)\n",
      "Requirement already satisfied: pillow in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from wordcloud) (8.0.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from matplotlib->wordcloud) (2020.12.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n",
      "Requirement already satisfied: ipywidgets in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (7.5.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipywidgets) (5.0.8)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipywidgets) (5.3.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipywidgets) (7.19.0)\n",
      "Requirement already satisfied: jupyter-client in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.7)\n",
      "Requirement already satisfied: tornado>=4.2 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.4)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.1)\n",
      "Requirement already satisfied: pygments in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.7.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (50.3.1.post20201107)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: decorator in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.6.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (20.3.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.1.4)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.1)\n",
      "Requirement already satisfied: prometheus-client in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (19.0.2)\n",
      "Requirement already satisfied: nbconvert in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: Send2Trash in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: jinja2 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.3)\n",
      "Requirement already satisfied: pycparser in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: testpath in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: bleach in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.2.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest-asyncio in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.2)\n",
      "Requirement already satisfied: async-generator in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: packaging in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.4)\n",
      "Requirement already satisfied: webencodings in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "Requirement already satisfied: tqdm in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (4.50.2)\n",
      "Requirement already satisfied: pydot in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from pydot) (2.4.7)\n",
      "Requirement already satisfied: pydotplus in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in /home/aiffel/anaconda3/envs/aiffel/lib/python3.8/site-packages (from pydotplus) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "# 기타 패키지 설치 (tensorflow 2.2.0 기준)\n",
    "! pip install tensorflow_addons==0.11.2\n",
    "! pip install sentencepiece\n",
    "! pip install wordcloud\n",
    "! pip install ipywidgets --user\n",
    "! pip install tqdm\n",
    "! pip install pydot\n",
    "! pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard                        2.3.0\r\n",
      "tensorboard-plugin-wit             1.6.0\r\n",
      "tensorflow                         2.2.0\r\n",
      "tensorflow-addons                  0.11.2\r\n",
      "tensorflow-datasets                4.2.0\r\n",
      "tensorflow-estimator               2.2.0\r\n",
      "tensorflow-metadata                0.28.0\r\n"
     ]
    }
   ],
   "source": [
    "#버전 호환성 확인 \n",
    "! pip list | grep tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#한국어 폰트 설치 확인\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KorQuAD 1.0 데이터 다운로드\n",
    "# $ wget https://korquad.github.io/dataset/KorQuAD_v1.0_train.json\n",
    "# $ wget https://korquad.github.io/dataset/KorQuAD_v1.0_dev.json\n",
    "# $ mv KorQuAD_v1.0* ~/aiffel/bert_qna/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, vocab, text corpus 데이터 다운로드\n",
    "\n",
    "# $ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/ko_32000.model\n",
    "# $ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/ko_32000.vocab\n",
    "# $ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/bert_pretrain_32000.hdf5\n",
    "\n",
    "# $ mv ko_32000* ~/aiffel/bert_qna/models\n",
    "# $ mv bert_pretrain_32000.hdf5 ~/aiffel/bert_qna/models\n",
    "\n",
    "# $ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/kowiki.txt.zip\n",
    "# $ mv kowiki.txt.zip ~/aiffel/bert_qna/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import collections\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#json 포맷 데ㅔ이터 확인용 함수 선언\n",
    "def print_json_tree(data, indent=\"\"):\n",
    "    for key, value in data.items():\n",
    "        if type(value) == list:     # list 형태의 item은 첫번째 item만 출력\n",
    "            print(f'{indent}- {key}: [{len(value)}]')\n",
    "            print_json_tree(value[0], indent + \"  \")\n",
    "        else:\n",
    "            print(f'{indent}- {key}: {value}')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- version: KorQuAD_v1.0_train\n",
      "- data: [1420]\n",
      "  - paragraphs: [3]\n",
      "    - qas: [8]\n",
      "      - answers: [1]\n",
      "        - text: 교향곡\n",
      "        - answer_start: 54\n",
      "      - id: 6566495-0-0\n",
      "      - question: 바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\n",
      "    - context: 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\n",
      "  - title: 파우스트_서곡\n"
     ]
    }
   ],
   "source": [
    "#데이터 경로 설정 및 모델 경로 설정\n",
    "data_dir = os.getenv('HOME')+'/aiffel/bert_qna/data'\n",
    "model_dir = os.getenv('HOME')+'/aiffel/bert_qna/models'\n",
    "\n",
    "# 훈련데이터 확인\n",
    "train_json_path = data_dir + '/KorQuAD_v1.0_train.json'\n",
    "with open(train_json_path) as f:\n",
    "    train_json = json.load(f)\n",
    "    print_json_tree(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- version: KorQuAD_v1.0_dev\n",
      "- data: [140]\n",
      "  - paragraphs: [2]\n",
      "    - qas: [7]\n",
      "      - answers: [1]\n",
      "        - text: 1989년 2월 15일\n",
      "        - answer_start: 0\n",
      "      - id: 6548850-0-0\n",
      "      - question: 임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?\n",
      "    - context: 1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "  - title: 임종석\n"
     ]
    }
   ],
   "source": [
    "# 검증데이터 확인\n",
    "dev_json_path = data_dir + '/KorQuAD_v1.0_dev.json'\n",
    "with open(dev_json_path) as f:\n",
    "    dev_json = json.load(f)\n",
    "    print_json_tree(dev_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"paragraphs\": [\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"교향곡\",\n",
      "              \"answer_start\": 54\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-0-0\",\n",
      "          \"question\": \"바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1악장\",\n",
      "              \"answer_start\": 421\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-0-1\",\n",
      "          \"question\": \"바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"베토벤의 교향곡 9번\",\n",
      "              \"answer_start\": 194\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-0-2\",\n",
      "          \"question\": \"바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"파우스트\",\n",
      "              \"answer_start\": 15\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-0-0\",\n",
      "          \"question\": \"1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"합창교향곡\",\n",
      "              \"answer_start\": 354\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-0-1\",\n",
      "          \"question\": \"파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1839\",\n",
      "              \"answer_start\": 0\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-0-0\",\n",
      "          \"question\": \"바그너가 파우스트를 처음으로 읽은 년도는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"파리\",\n",
      "              \"answer_start\": 410\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-0-1\",\n",
      "          \"question\": \"바그너가 처음 교향곡 작곡을 한 장소는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"드레스덴\",\n",
      "              \"answer_start\": 534\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-0-2\",\n",
      "          \"question\": \"바그너의 1악장의 초연은 어디서 연주되었는가?\"\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"한스 폰 뷜로\",\n",
      "              \"answer_start\": 402\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-1-0\",\n",
      "          \"question\": \"바그너의 작품을 시인의 피로 쓰여졌다고 극찬한 것은 누구인가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"리스트\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-1-1\",\n",
      "          \"question\": \"잊혀져 있는 파우스트 서곡 1악장을 부활시킨 것은 누구인가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"20루이의 금\",\n",
      "              \"answer_start\": 345\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-1-2\",\n",
      "          \"question\": \"바그너는 다시 개정된 총보를 얼마를 받고 팔았는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"리스트\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-1-0\",\n",
      "          \"question\": \"파우스트 교향곡을 부활시킨 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"한스 폰 뷜로\",\n",
      "              \"answer_start\": 402\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-1-1\",\n",
      "          \"question\": \"파우스트 교향곡을 피아노 독주용으로 편곡한 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"리스트\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-1-0\",\n",
      "          \"question\": \"1악장을 부활시켜 연주한 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"한스 폰 뷜로\",\n",
      "              \"answer_start\": 402\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-1-1\",\n",
      "          \"question\": \"파우스트 교향곡에 감탄하여 피아노곡으로 편곡한 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1840년\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-1-2\",\n",
      "          \"question\": \"리스트가 바그너와 알게 된 연도는?\"\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"한편 1840년부터 바그너와 알고 지내던 리스트가 잊혀져 있던 1악장을 부활시켜 1852년에 바이마르에서 연주했다. 이것을 계기로 바그너도 이 작품에 다시 관심을 갖게 되었고, 그 해 9월에는 총보의 반환을 요구하여 이를 서곡으로 간추린 다음 수정을 했고 브라이트코프흐 & 헤르텔 출판사에서 출판할 개정판도 준비했다. 1853년 5월에는 리스트가 이 작품이 수정되었다는 것을 인정했지만, 끝내 바그너의 출판 계획은 무산되고 말았다. 이후 1855년에 리스트가 자신의 작품 파우스트 교향곡을 거의 완성하여 그 사실을 바그너에게 알렸고, 바그너는 다시 개정된 총보를 리스트에게 보내고 브라이트코프흐 & 헤르텔 출판사에는 20루이의 금을 받고 팔았다. 또한 그의 작품을 “하나하나의 음표가 시인의 피로 쓰여졌다”며 극찬했던 한스 폰 뷜로가 그것을 피아노 독주용으로 편곡했는데, 리스트는 그것을 약간 변형되었을 뿐이라고 지적했다. 이 서곡의 총보 첫머리에는 파우스트 1부의 내용 중 한 구절을 인용하고 있다.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"주제, 동기\",\n",
      "              \"answer_start\": 70\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-2-0\",\n",
      "          \"question\": \"서주에는 무엇이 암시되어 있는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"제1바이올린\",\n",
      "              \"answer_start\": 148\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-2-1\",\n",
      "          \"question\": \"첫부분에는 어떤 악기를 사용해 더욱 명확하게 나타내는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"소나타 형식\",\n",
      "              \"answer_start\": 272\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-2-2\",\n",
      "          \"question\": \"주요부는 어떤 형식으로 되어 있는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"저음 주제\",\n",
      "              \"answer_start\": 102\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-2-0\",\n",
      "          \"question\": \"첫 부분의 주요주제를 암시하는 주제는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"D장조\",\n",
      "              \"answer_start\": 409\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-2-1\",\n",
      "          \"question\": \"제2주제의 축소된 재현부의 조성은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"4/4박자\",\n",
      "              \"answer_start\": 35\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-2-0\",\n",
      "          \"question\": \"곡이 시작할때의 박자는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"고뇌와 갈망 동기, 청춘의 사랑 동기\",\n",
      "              \"answer_start\": 115\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-2-1\",\n",
      "          \"question\": \"이 곡의 주요 주제는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"D장조\",\n",
      "              \"answer_start\": 409\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-2-2\",\n",
      "          \"question\": \"제 2주제에선 무슨 장조로 재현되는가?\"\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"이 작품은 라단조, Sehr gehalten(아주 신중하게), 4/4박자의 부드러운 서주로 서주로 시작되는데, 여기에는 주요 주제, 동기의 대부분이 암시, 예고되어 있다. 첫 부분의 저음 주제는 주요 주제(고뇌와 갈망 동기, 청춘의 사랑 동기)를 암시하고 있으며, 제1바이올린으로 더욱 명확하게 나타난다. 또한 그것을 이어받는 동기도 중요한 역할을 한다. 여기에 새로운 소재가 더해진 뒤에 새로운 주제도 연주된다. 주요부는 Sehr bewegt(아주 격동적으로), 2/2박자의 자유로운 소나타 형식으로 매우 드라마틱한 구상과 유기적인 구성을 하고 있다. 여기에는 지금까지의 주제나 소재 외에도 오보에에 의한 선율과 제2주제를 떠올리게 하는 부차적인 주제가 더해지는데, 중간부에서는 약보3이 중심이 되고 제2주제는 축소된 재현부에서 D장조로 재현된다. 마지막에는 주요 주제를 회상하면서 조용히 마친다.\"\n",
      "    }\n",
      "  ],\n",
      "  \"title\": \"파우스트_서곡\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(train_json[\"data\"][0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 전처리 1) : 띄어쓰기 단위 정보 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('파우스트', '파우스트')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터셋 전처리_띄어쓰기 단위 정보관리를 위한 함수 선언\n",
    "\n",
    "def _is_whitespace(c):\n",
    "    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# whitespace가 2개인 경우를 처리하는 예시\n",
    "\n",
    "string1 = '1839년 파우스트을 읽었다.'\n",
    "string2 = '1839년  파우스트을 읽었다.'\n",
    "string1[6:10], string2[7:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1' : ['1'] : [0]\n",
      "'8' : ['18'] : [0, 0]\n",
      "'3' : ['183'] : [0, 0, 0]\n",
      "'9' : ['1839'] : [0, 0, 0, 0]\n",
      "'년' : ['1839년'] : [0, 0, 0, 0, 0]\n",
      "' ' : ['1839년'] : [0, 0, 0, 0, 0, 0]\n",
      "'파' : ['1839년', '파'] : [0, 0, 0, 0, 0, 0, 1]\n",
      "'우' : ['1839년', '파우'] : [0, 0, 0, 0, 0, 0, 1, 1]\n",
      "'스' : ['1839년', '파우스'] : [0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
      "'트' : ['1839년', '파우스트'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "'을' : ['1839년', '파우스트을'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "' ' : ['1839년', '파우스트을'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "'읽' : ['1839년', '파우스트을', '읽'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2]\n",
      "'었' : ['1839년', '파우스트을', '읽었'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2]\n",
      "'다' : ['1839년', '파우스트을', '읽었다'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2]\n",
      "'.' : ['1839년', '파우스트을', '읽었다.'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "word_tokens = []\n",
    "char_to_word = []\n",
    "prev_is_whitespace = True\n",
    "\n",
    "# 첫번째 문장(string1)에 대해 띄어쓰기 영역 정보를 표시\n",
    "for c in string1:\n",
    "    if _is_whitespace(c):\n",
    "        prev_is_whitespace = True\n",
    "    else:\n",
    "        if prev_is_whitespace:\n",
    "            word_tokens.append(c)\n",
    "        else:\n",
    "            word_tokens[-1] += c\n",
    "        prev_is_whitespace = False    \n",
    "    char_to_word.append(len(word_tokens) - 1)\n",
    "    print(f'\\'{c}\\' : {word_tokens} : {char_to_word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1' : ['1'] : [0]\n",
      "'8' : ['18'] : [0, 0]\n",
      "'3' : ['183'] : [0, 0, 0]\n",
      "'9' : ['1839'] : [0, 0, 0, 0]\n",
      "'년' : ['1839년'] : [0, 0, 0, 0, 0]\n",
      "' ' : ['1839년'] : [0, 0, 0, 0, 0, 0]\n",
      "' ' : ['1839년'] : [0, 0, 0, 0, 0, 0, 0]\n",
      "'파' : ['1839년', '파'] : [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "'우' : ['1839년', '파우'] : [0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "'스' : ['1839년', '파우스'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
      "'트' : ['1839년', '파우스트'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "'을' : ['1839년', '파우스트을'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "' ' : ['1839년', '파우스트을'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "'읽' : ['1839년', '파우스트을', '읽'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2]\n",
      "'었' : ['1839년', '파우스트을', '읽었'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2]\n",
      "'다' : ['1839년', '파우스트을', '읽었다'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2]\n",
      "'.' : ['1839년', '파우스트을', '읽었다.'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "word_tokens = []\n",
    "char_to_word = []\n",
    "prev_is_whitespace = True\n",
    "\n",
    "# 두번째 문장(string2)에 대해 띄어쓰기 영역 정보를 표시\n",
    "for c in string2:\n",
    "    if _is_whitespace(c):\n",
    "        prev_is_whitespace = True\n",
    "    else:\n",
    "        if prev_is_whitespace:\n",
    "            word_tokens.append(c)\n",
    "        else:\n",
    "            word_tokens[-1] += c\n",
    "        prev_is_whitespace = False    \n",
    "    char_to_word.append(len(word_tokens) - 1)\n",
    "    print(f'\\'{c}\\' : {word_tokens} : {char_to_word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 전처리_띄어쓰기 단위 정보관리를 위한 함수 선언\n",
    "#원래 데이터가 띄어쓰기 단위로 어떠했었는지 word token 영역별로 추가 정보를 관리\n",
    "def _tokenize_whitespace(string):\n",
    "    word_tokens = []\n",
    "    char_to_word = [] \n",
    "    prev_is_whitespace = True\n",
    "\n",
    "    for c in string:\n",
    "        if _is_whitespace(c):\n",
    "            prev_is_whitespace = True\n",
    "        else:\n",
    "            if prev_is_whitespace:\n",
    "                word_tokens.append(c)\n",
    "            else:\n",
    "                word_tokens[-1] += c\n",
    "            prev_is_whitespace = False    \n",
    "        char_to_word.append(len(word_tokens) - 1)\n",
    "    \n",
    "    return word_tokens, char_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1' : 0\n",
      "'8' : 0\n",
      "'3' : 0\n",
      "'9' : 0\n",
      "'년' : 0\n",
      "' ' : 0\n",
      "'파' : 1\n",
      "'우' : 1\n",
      "'스' : 1\n",
      "'트' : 1\n",
      "'을' : 1\n",
      "' ' : 1\n",
      "'읽' : 2\n",
      "'었' : 2\n",
      "'다' : 2\n",
      "'.' : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['1839년', '파우스트을', '읽었다.'], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 문장(string1)에 대해 띄어쓰기 영역 정보를 표시\n",
    "word_tokens, char_to_word = _tokenize_whitespace(string1)\n",
    "for c, i in zip(list(string1), char_to_word):\n",
    "    print(f'\\'{c}\\' : {i}')\n",
    "\n",
    "word_tokens, char_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1' : 0\n",
      "'8' : 0\n",
      "'3' : 0\n",
      "'9' : 0\n",
      "'년' : 0\n",
      "' ' : 0\n",
      "' ' : 0\n",
      "'파' : 1\n",
      "'우' : 1\n",
      "'스' : 1\n",
      "'트' : 1\n",
      "'을' : 1\n",
      "' ' : 1\n",
      "'읽' : 2\n",
      "'었' : 2\n",
      "'다' : 2\n",
      "'.' : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['1839년', '파우스트을', '읽었다.'],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두번째 문장(string2)에 대해 띄어쓰기 영역 정보를 표시\n",
    "word_tokens, char_to_word = _tokenize_whitespace(string2)\n",
    "for c, i in zip(list(string2), char_to_word):\n",
    "    print(f'\\'{c}\\' : {i}')\n",
    "\n",
    "word_tokens, char_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 전처리 2) : Tokenize by Vocab\n",
    "- 읽었다 -> 읽 + 었다 로 처리하기 위한 접근법\n",
    "- subword segmentation\n",
    "    - WordPiece(BERT)\n",
    "    - SentencePiece => 언어마다 다른 문법 규칙을 활용하지 않음(통계적 방법)\n",
    "    - koNLPy (형태소분석기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁1839', '년', '▁', '파우스트', '을', '▁읽', '었다', '.'], [0, 2, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_32000.model\")\n",
    "\n",
    "# word를 subword로 변경하면서 index 저장\n",
    "word_to_token = []\n",
    "context_tokens = []\n",
    "for (i, word) in enumerate(word_tokens):\n",
    "    word_to_token.append(len(context_tokens))\n",
    "    tokens = vocab.encode_as_pieces(word)  # SentencePiece를 사용해 Subword로 쪼갭니다.\n",
    "    for token in tokens:\n",
    "        context_tokens.append(token)\n",
    "\n",
    "context_tokens, word_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize_vocab(vocab, context_words):\n",
    "    word_to_token = []\n",
    "    context_tokens = []\n",
    "    for (i, word) in enumerate(context_words):\n",
    "        word_to_token.append(len(context_tokens))\n",
    "        tokens = vocab.encode_as_pieces(word)\n",
    "        for token in tokens:\n",
    "            context_tokens.append(token)\n",
    "    return context_tokens, word_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1839년', '파우스트을', '읽었다.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['▁1839', '년', '▁', '파우스트', '을', '▁읽', '었다', '.'], [0, 2, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_tokens)  # 처리해야 할 word 단위 입력\n",
    "\n",
    "context_tokens, word_to_token = _tokenize_vocab(vocab, word_tokens)\n",
    "context_tokens, word_to_token   # Subword 단위로 토큰화한 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 전처리 3) : Improve Span\n",
    "    - KorQuAD => Context , Question , Answer 추출하기\n",
    "    - 질문(question)과 지문(context) 입력으로 주고 \n",
    "    - 지문 영역에서 정답(answer)를 찾도록 구성 됨\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[context]  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\n",
      "[question]  바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\n",
      "[answer]  교향곡\n",
      "[answer_start] index:  54 character:  교\n",
      "[answer_end]index:  56 character:  곡\n"
     ]
    }
   ],
   "source": [
    "context = train_json['data'][0]['paragraphs'][0]['context']\n",
    "question = train_json['data'][0]['paragraphs'][0]['qas'][0]['question']\n",
    "answer_text = train_json['data'][0]['paragraphs'][0]['qas'][0]['answers'][0]['text']\n",
    "answer_start = train_json['data'][0]['paragraphs'][0]['qas'][0]['answers'][0]['answer_start']\n",
    "answer_end = answer_start + len(answer_text) - 1\n",
    "\n",
    "print('[context] ', context)\n",
    "print('[question] ', question)\n",
    "print('[answer] ', answer_text)\n",
    "print('[answer_start] index: ', answer_start, 'character: ', context[answer_start])\n",
    "print('[answer_end]index: ', answer_end, 'character: ', context[answer_end])\n",
    "\n",
    "# answer_text에 해당하는 context 영역을 정확히 찾아내야 합니다. \n",
    "assert context[answer_start:answer_end + 1] == answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1839년', '바그너는', '괴테의', '파우스트을', '처음', '읽고', '그', '내용에', '마음이', '끌려', '이를', '소재로', '해서', '하나의', '교향곡을', '쓰려는', '뜻을', '갖는다.', '이', '시기']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3],\n",
       " '1839년 바그너는 괴테의 파우스트을')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context를 띄어쓰기(word) 단위로 토큰화한 결과를 살펴봅니다. \n",
    "word_tokens, char_to_word = _tokenize_whitespace(context)\n",
    "\n",
    "print( word_tokens[:20])\n",
    "\n",
    "char_to_word[:20], context[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['▁1839', '년']\n",
      "2 ['▁바그너', '는']\n",
      "4 ['▁괴테', '의']\n",
      "6 ['▁', '파우스트', '을']\n",
      "9 ['▁처음']\n",
      "10 ['▁읽고']\n",
      "11 ['▁그']\n",
      "12 ['▁내용에']\n",
      "13 ['▁마음이']\n",
      "14 ['▁끌려']\n",
      "15 ['▁이를']\n",
      "16 ['▁소재로']\n",
      "17 ['▁해서']\n",
      "18 ['▁하나의']\n",
      "19 ['▁교향곡', '을']\n",
      "21 ['▁쓰', '려는']\n",
      "23 ['▁뜻을']\n",
      "24 ['▁갖는다', '.']\n",
      "26 ['▁이']\n",
      "27 ['▁시기']\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기(word) 단위로 쪼개진 context(word_tokens)를 Subword로 토큰화한 결과를 살펴봅니다. \n",
    "context_tokens, word_to_token = _tokenize_vocab(vocab, word_tokens)\n",
    "for i in range(min(20, len(word_to_token) - 1)):\n",
    "    print(word_to_token[i], context_tokens[word_to_token[i]:word_to_token[i + 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14, '교향곡', ['교향곡을'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer_start와 answer_end로부터 word_start와 word_end를 구합니다. \n",
    "word_start = char_to_word[answer_start]\n",
    "word_end = char_to_word[answer_end]\n",
    "word_start, word_end, answer_text, word_tokens[word_start:word_end + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 20, ['▁교향곡', '을'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_start = word_to_token[word_start]\n",
    "if word_end < len(word_to_token) - 1:\n",
    "    token_end = word_to_token[word_end + 1] - 1\n",
    "else:\n",
    "    token_end = len(context_tokens) - 1\n",
    "token_start, token_end, context_tokens[token_start:token_end + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁교향곡'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 정답인 answer_text도 Subword 기준으로 토큰화해 둡니다. \n",
    "token_answer = \" \".join(vocab.encode_as_pieces(answer_text))\n",
    "token_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X >> (19, 20) ▁교향곡 을\n",
      "O >> (19, 19) ▁교향곡\n",
      "X >> (20, 20) 을\n"
     ]
    }
   ],
   "source": [
    "# 정답이 될수 있는 new_start와 new_end의 경우를 순회탐색합니다. \n",
    "for new_start in range(token_start, token_end + 1):\n",
    "    for new_end in range(token_end, new_start - 1, -1):\n",
    "        text_span = \" \".join(context_tokens[new_start : (new_end + 1)])\n",
    "        if text_span == token_answer:   # 정답과 일치하는 경우\n",
    "            print(\"O >>\", (new_start, new_end), text_span)\n",
    "        else:\n",
    "            print(\"X >>\", (new_start, new_end), text_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_tokens에서 char_answer의 위치를 찾아 리턴하는 함수\n",
    "def _improve_span(vocab, context_tokens, token_start, token_end, char_answer):\n",
    "    token_answer = \" \".join(vocab.encode_as_pieces(char_answer))\n",
    "    for new_start in range(token_start, token_end + 1):\n",
    "        for new_end in range(token_end, new_start - 1, -1):\n",
    "            text_span = \" \".join(context_tokens[new_start : (new_end + 1)])\n",
    "            if text_span == token_answer:\n",
    "                return (new_start, new_end)\n",
    "    return (token_start, token_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_start: 19  token_end: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁교향곡']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_start, token_end = _improve_span(vocab, context_tokens, token_start, token_end, answer_text)\n",
    "print('token_start:', token_start, ' token_end:', token_end)\n",
    "context_tokens[token_start:token_end + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 전처리 4) : 데이터셋 분리\n",
    "    -train / dev \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_korquad(vocab, json_data, out_file):\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for data in tqdm(json_data[\"data\"]):\n",
    "            title = data[\"title\"]\n",
    "            for paragraph in data[\"paragraphs\"]:\n",
    "                context = paragraph[\"context\"]\n",
    "                context_words, char_to_word = _tokenize_whitespace(context)\n",
    "\n",
    "                for qa in paragraph[\"qas\"]:\n",
    "                    assert len(qa[\"answers\"]) == 1\n",
    "                    qa_id = qa[\"id\"]\n",
    "                    question = qa[\"question\"]\n",
    "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                    answer_start = qa[\"answers\"][0][\"answer_start\"]\n",
    "                    answer_end = answer_start + len(answer_text) - 1\n",
    "\n",
    "                    assert answer_text == context[answer_start:answer_end + 1]\n",
    "\n",
    "                    word_start = char_to_word[answer_start]\n",
    "                    word_end = char_to_word[answer_end]\n",
    "\n",
    "                    word_answer = \" \".join(context_words[word_start:word_end + 1])\n",
    "                    char_answer = \" \".join(answer_text.strip().split())\n",
    "                    assert char_answer in word_answer\n",
    "\n",
    "                    context_tokens, word_to_token = _tokenize_vocab(vocab, context_words)\n",
    "\n",
    "                    token_start = word_to_token[word_start]\n",
    "                    if word_end < len(word_to_token) - 1:\n",
    "                        token_end = word_to_token[word_end + 1] - 1\n",
    "                    else:\n",
    "                        token_end = len(context_tokens) - 1\n",
    "\n",
    "                    token_start, token_end = _improve_span(vocab, context_tokens, token_start, token_end, char_answer)\n",
    "\n",
    "                    data = {\"qa_id\": qa_id, \"title\": title, \"question\": vocab.encode_as_pieces(question), \"context\": context_tokens, \"answer\": char_answer, \"token_start\": token_start, \"token_end\":token_end}\n",
    "                    f.write(json.dumps(data, ensure_ascii=False))\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c631ec70c643238f0d3e158b2f9da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1420.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cebd5dc2111491a892125e7421d7190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=140.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 전처리를 수행하여 파일로 생성합니다. \n",
    "dump_korquad(vocab, train_json, f\"{data_dir}/korquad_train.json\")\n",
    "dump_korquad(vocab, dev_json, f\"{data_dir}/korquad_dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"qa_id\": \"6566495-0-0\", \"title\": \"파우스트_서곡\", \"question\": [\"▁바그너\", \"는\", \"▁괴테\", \"의\", \"▁\", \"파우스트\", \"를\", \"▁읽고\", \"▁무엇을\", \"▁쓰고\", \"자\", \"▁\", \"했\", \"는\", \"가\", \"?\"], \"context\": [\"▁1839\", \"년\", \"▁바그너\", \"는\", \"▁괴테\", \"의\", \"▁\", \"파우스트\", \"을\", \"▁처음\", \"▁읽고\", \"▁그\", \"▁내용에\", \"▁마음이\", \"▁끌려\", \"▁이를\", \"▁소재로\", \"▁해서\", \"▁하나의\", \"▁교향곡\", \"을\", \"▁쓰\", \"려는\", \"▁뜻을\", \"▁갖는다\", \".\", \"▁이\", \"▁시기\", \"▁바그너\", \"는\", \"▁1838\", \"년에\", \"▁빛\", \"▁독\", \"촉\", \"으로\", \"▁산\", \"전\", \"수\", \"전을\", \"▁다\", \"▁\", \"걲\", \"은\", \"▁상황이\", \"라\", \"▁좌절\", \"과\", \"▁실망\", \"에\", \"▁가득\", \"했으며\", \"▁메\", \"피스\", \"토\", \"펠\", \"레스\", \"를\", \"▁만나는\", \"▁\", \"파우스트\", \"의\", \"▁심\", \"경에\", \"▁공감\", \"했다고\", \"▁한다\", \".\", \"▁또한\", \"▁파리에서\", \"▁아브\", \"네\", \"크의\", \"▁지휘\", \"로\", \"▁파리\", \"▁음악원\", \"▁관현악단\", \"이\", \"▁연주하는\", \"▁베토벤\", \"의\", \"▁교향곡\", \"▁9\", \"번을\", \"▁듣고\", \"▁깊은\", \"▁감\", \"명을\", \"▁받았는데\", \",\", \"▁이것이\", \"▁이듬해\", \"▁1\", \"월에\", \"▁\", \"파우스트\", \"의\", \"▁서\", \"곡으로\", \"▁쓰여진\", \"▁이\", \"▁작품에\", \"▁조금\", \"이라도\", \"▁영향을\", \"▁끼\", \"쳤\", \"으리라\", \"는\", \"▁것은\", \"▁의심\", \"할\", \"▁여지가\", \"▁없다\", \".\", \"▁여기\", \"의\", \"▁라\", \"단\", \"조\", \"▁조성\", \"의\", \"▁경우에도\", \"▁그의\", \"▁전기\", \"에\", \"▁적혀\", \"▁있는\", \"▁것처럼\", \"▁단순한\", \"▁정신적\", \"▁피로\", \"나\", \"▁실\", \"의\", \"가\", \"▁반영\", \"된\", \"▁것이\", \"▁아니라\", \"▁베토벤\", \"의\", \"▁합창\", \"교\", \"향\", \"곡\", \"▁조성\", \"의\", \"▁영향을\", \"▁받은\", \"▁것을\", \"▁볼\", \"▁수\", \"▁있다\", \".\", \"▁그렇게\", \"▁교향곡\", \"▁작곡\", \"을\", \"▁1839\", \"년부터\", \"▁40\", \"년에\", \"▁걸쳐\", \"▁파리에서\", \"▁착수\", \"했으나\", \"▁1\", \"악장\", \"을\", \"▁쓴\", \"▁뒤에\", \"▁중단\", \"했다\", \".\", \"▁또한\", \"▁작품의\", \"▁완성\", \"과\", \"▁동시에\", \"▁그는\", \"▁이\", \"▁서\", \"곡\", \"(1\", \"악장\", \")\", \"을\", \"▁파리\", \"▁음악원\", \"의\", \"▁연주회\", \"에서\", \"▁연주\", \"할\", \"▁파트\", \"보\", \"까지\", \"▁준비\", \"하였으나\", \",\", \"▁실제로는\", \"▁이루어지지\", \"는\", \"▁않았다\", \".\", \"▁결국\", \"▁초연\", \"은\", \"▁4\", \"년\", \"▁반\", \"이\", \"▁지난\", \"▁후에\", \"▁드레스덴\", \"에서\", \"▁연주\", \"되었고\", \"▁재\", \"연\", \"도\", \"▁이루어졌\", \"지만\", \",\", \"▁이후에\", \"▁그대로\", \"▁방치\", \"되고\", \"▁말았다\", \".\", \"▁그\", \"▁사이에\", \"▁그는\", \"▁리\", \"엔\", \"치\", \"와\", \"▁방\", \"황\", \"하는\", \"▁네덜란드\", \"인\", \"을\", \"▁완성\", \"하고\", \"▁탄\", \"호\", \"이\", \"저\", \"에도\", \"▁착수\", \"하는\", \"▁등\", \"▁분\", \"주\", \"한\", \"▁시간을\", \"▁보\", \"냈는데\", \",\", \"▁그런\", \"▁바쁜\", \"▁생활\", \"이\", \"▁이\", \"▁곡을\", \"▁잊\", \"게\", \"▁한\", \"▁것이\", \"▁아닌\", \"가\", \"▁하는\", \"▁의견도\", \"▁있다\", \".\"], \"answer\": \"교향곡\", \"token_start\": 19, \"token_end\": 19}\n",
      "{\"qa_id\": \"6566495-0-1\", \"title\": \"파우스트_서곡\", \"question\": [\"▁바그너\", \"는\", \"▁교향곡\", \"▁작곡\", \"을\", \"▁어디\", \"까지\", \"▁쓴\", \"▁뒤에\", \"▁중단\", \"했\", \"는\", \"가\", \"?\"], \"context\": [\"▁1839\", \"년\", \"▁바그너\", \"는\", \"▁괴테\", \"의\", \"▁\", \"파우스트\", \"을\", \"▁처음\", \"▁읽고\", \"▁그\", \"▁내용에\", \"▁마음이\", \"▁끌려\", \"▁이를\", \"▁소재로\", \"▁해서\", \"▁하나의\", \"▁교향곡\", \"을\", \"▁쓰\", \"려는\", \"▁뜻을\", \"▁갖는다\", \".\", \"▁이\", \"▁시기\", \"▁바그너\", \"는\", \"▁1838\", \"년에\", \"▁빛\", \"▁독\", \"촉\", \"으로\", \"▁산\", \"전\", \"수\", \"전을\", \"▁다\", \"▁\", \"걲\", \"은\", \"▁상황이\", \"라\", \"▁좌절\", \"과\", \"▁실망\", \"에\", \"▁가득\", \"했으며\", \"▁메\", \"피스\", \"토\", \"펠\", \"레스\", \"를\", \"▁만나는\", \"▁\", \"파우스트\", \"의\", \"▁심\", \"경에\", \"▁공감\", \"했다고\", \"▁한다\", \".\", \"▁또한\", \"▁파리에서\", \"▁아브\", \"네\", \"크의\", \"▁지휘\", \"로\", \"▁파리\", \"▁음악원\", \"▁관현악단\", \"이\", \"▁연주하는\", \"▁베토벤\", \"의\", \"▁교향곡\", \"▁9\", \"번을\", \"▁듣고\", \"▁깊은\", \"▁감\", \"명을\", \"▁받았는데\", \",\", \"▁이것이\", \"▁이듬해\", \"▁1\", \"월에\", \"▁\", \"파우스트\", \"의\", \"▁서\", \"곡으로\", \"▁쓰여진\", \"▁이\", \"▁작품에\", \"▁조금\", \"이라도\", \"▁영향을\", \"▁끼\", \"쳤\", \"으리라\", \"는\", \"▁것은\", \"▁의심\", \"할\", \"▁여지가\", \"▁없다\", \".\", \"▁여기\", \"의\", \"▁라\", \"단\", \"조\", \"▁조성\", \"의\", \"▁경우에도\", \"▁그의\", \"▁전기\", \"에\", \"▁적혀\", \"▁있는\", \"▁것처럼\", \"▁단순한\", \"▁정신적\", \"▁피로\", \"나\", \"▁실\", \"의\", \"가\", \"▁반영\", \"된\", \"▁것이\", \"▁아니라\", \"▁베토벤\", \"의\", \"▁합창\", \"교\", \"향\", \"곡\", \"▁조성\", \"의\", \"▁영향을\", \"▁받은\", \"▁것을\", \"▁볼\", \"▁수\", \"▁있다\", \".\", \"▁그렇게\", \"▁교향곡\", \"▁작곡\", \"을\", \"▁1839\", \"년부터\", \"▁40\", \"년에\", \"▁걸쳐\", \"▁파리에서\", \"▁착수\", \"했으나\", \"▁1\", \"악장\", \"을\", \"▁쓴\", \"▁뒤에\", \"▁중단\", \"했다\", \".\", \"▁또한\", \"▁작품의\", \"▁완성\", \"과\", \"▁동시에\", \"▁그는\", \"▁이\", \"▁서\", \"곡\", \"(1\", \"악장\", \")\", \"을\", \"▁파리\", \"▁음악원\", \"의\", \"▁연주회\", \"에서\", \"▁연주\", \"할\", \"▁파트\", \"보\", \"까지\", \"▁준비\", \"하였으나\", \",\", \"▁실제로는\", \"▁이루어지지\", \"는\", \"▁않았다\", \".\", \"▁결국\", \"▁초연\", \"은\", \"▁4\", \"년\", \"▁반\", \"이\", \"▁지난\", \"▁후에\", \"▁드레스덴\", \"에서\", \"▁연주\", \"되었고\", \"▁재\", \"연\", \"도\", \"▁이루어졌\", \"지만\", \",\", \"▁이후에\", \"▁그대로\", \"▁방치\", \"되고\", \"▁말았다\", \".\", \"▁그\", \"▁사이에\", \"▁그는\", \"▁리\", \"엔\", \"치\", \"와\", \"▁방\", \"황\", \"하는\", \"▁네덜란드\", \"인\", \"을\", \"▁완성\", \"하고\", \"▁탄\", \"호\", \"이\", \"저\", \"에도\", \"▁착수\", \"하는\", \"▁등\", \"▁분\", \"주\", \"한\", \"▁시간을\", \"▁보\", \"냈는데\", \",\", \"▁그런\", \"▁바쁜\", \"▁생활\", \"이\", \"▁이\", \"▁곡을\", \"▁잊\", \"게\", \"▁한\", \"▁것이\", \"▁아닌\", \"가\", \"▁하는\", \"▁의견도\", \"▁있다\", \".\"], \"answer\": \"1악장\", \"token_start\": 168, \"token_end\": 169}\n",
      "{\"qa_id\": \"6566495-0-2\", \"title\": \"파우스트_서곡\", \"question\": [\"▁바그너\", \"가\", \"▁\", \"파우스트\", \"▁서\", \"곡을\", \"▁쓸\", \"▁때\", \"▁어떤\", \"▁곡\", \"의\", \"▁영향을\", \"▁받았\", \"는\", \"가\", \"?\"], \"context\": [\"▁1839\", \"년\", \"▁바그너\", \"는\", \"▁괴테\", \"의\", \"▁\", \"파우스트\", \"을\", \"▁처음\", \"▁읽고\", \"▁그\", \"▁내용에\", \"▁마음이\", \"▁끌려\", \"▁이를\", \"▁소재로\", \"▁해서\", \"▁하나의\", \"▁교향곡\", \"을\", \"▁쓰\", \"려는\", \"▁뜻을\", \"▁갖는다\", \".\", \"▁이\", \"▁시기\", \"▁바그너\", \"는\", \"▁1838\", \"년에\", \"▁빛\", \"▁독\", \"촉\", \"으로\", \"▁산\", \"전\", \"수\", \"전을\", \"▁다\", \"▁\", \"걲\", \"은\", \"▁상황이\", \"라\", \"▁좌절\", \"과\", \"▁실망\", \"에\", \"▁가득\", \"했으며\", \"▁메\", \"피스\", \"토\", \"펠\", \"레스\", \"를\", \"▁만나는\", \"▁\", \"파우스트\", \"의\", \"▁심\", \"경에\", \"▁공감\", \"했다고\", \"▁한다\", \".\", \"▁또한\", \"▁파리에서\", \"▁아브\", \"네\", \"크의\", \"▁지휘\", \"로\", \"▁파리\", \"▁음악원\", \"▁관현악단\", \"이\", \"▁연주하는\", \"▁베토벤\", \"의\", \"▁교향곡\", \"▁9\", \"번을\", \"▁듣고\", \"▁깊은\", \"▁감\", \"명을\", \"▁받았는데\", \",\", \"▁이것이\", \"▁이듬해\", \"▁1\", \"월에\", \"▁\", \"파우스트\", \"의\", \"▁서\", \"곡으로\", \"▁쓰여진\", \"▁이\", \"▁작품에\", \"▁조금\", \"이라도\", \"▁영향을\", \"▁끼\", \"쳤\", \"으리라\", \"는\", \"▁것은\", \"▁의심\", \"할\", \"▁여지가\", \"▁없다\", \".\", \"▁여기\", \"의\", \"▁라\", \"단\", \"조\", \"▁조성\", \"의\", \"▁경우에도\", \"▁그의\", \"▁전기\", \"에\", \"▁적혀\", \"▁있는\", \"▁것처럼\", \"▁단순한\", \"▁정신적\", \"▁피로\", \"나\", \"▁실\", \"의\", \"가\", \"▁반영\", \"된\", \"▁것이\", \"▁아니라\", \"▁베토벤\", \"의\", \"▁합창\", \"교\", \"향\", \"곡\", \"▁조성\", \"의\", \"▁영향을\", \"▁받은\", \"▁것을\", \"▁볼\", \"▁수\", \"▁있다\", \".\", \"▁그렇게\", \"▁교향곡\", \"▁작곡\", \"을\", \"▁1839\", \"년부터\", \"▁40\", \"년에\", \"▁걸쳐\", \"▁파리에서\", \"▁착수\", \"했으나\", \"▁1\", \"악장\", \"을\", \"▁쓴\", \"▁뒤에\", \"▁중단\", \"했다\", \".\", \"▁또한\", \"▁작품의\", \"▁완성\", \"과\", \"▁동시에\", \"▁그는\", \"▁이\", \"▁서\", \"곡\", \"(1\", \"악장\", \")\", \"을\", \"▁파리\", \"▁음악원\", \"의\", \"▁연주회\", \"에서\", \"▁연주\", \"할\", \"▁파트\", \"보\", \"까지\", \"▁준비\", \"하였으나\", \",\", \"▁실제로는\", \"▁이루어지지\", \"는\", \"▁않았다\", \".\", \"▁결국\", \"▁초연\", \"은\", \"▁4\", \"년\", \"▁반\", \"이\", \"▁지난\", \"▁후에\", \"▁드레스덴\", \"에서\", \"▁연주\", \"되었고\", \"▁재\", \"연\", \"도\", \"▁이루어졌\", \"지만\", \",\", \"▁이후에\", \"▁그대로\", \"▁방치\", \"되고\", \"▁말았다\", \".\", \"▁그\", \"▁사이에\", \"▁그는\", \"▁리\", \"엔\", \"치\", \"와\", \"▁방\", \"황\", \"하는\", \"▁네덜란드\", \"인\", \"을\", \"▁완성\", \"하고\", \"▁탄\", \"호\", \"이\", \"저\", \"에도\", \"▁착수\", \"하는\", \"▁등\", \"▁분\", \"주\", \"한\", \"▁시간을\", \"▁보\", \"냈는데\", \",\", \"▁그런\", \"▁바쁜\", \"▁생활\", \"이\", \"▁이\", \"▁곡을\", \"▁잊\", \"게\", \"▁한\", \"▁것이\", \"▁아닌\", \"가\", \"▁하는\", \"▁의견도\", \"▁있다\", \".\"], \"answer\": \"베토벤의 교향곡 9번\", \"token_start\": 80, \"token_end\": 84}\n",
      "{\"qa_id\": \"6566518-0-0\", \"title\": \"파우스트_서곡\", \"question\": [\"▁1839\", \"년\", \"▁바그너\", \"가\", \"▁교향곡\", \"의\", \"▁소재로\", \"▁쓰\", \"려고\", \"▁했던\", \"▁책은\", \"?\"], \"context\": [\"▁1839\", \"년\", \"▁바그너\", \"는\", \"▁괴테\", \"의\", \"▁\", \"파우스트\", \"을\", \"▁처음\", \"▁읽고\", \"▁그\", \"▁내용에\", \"▁마음이\", \"▁끌려\", \"▁이를\", \"▁소재로\", \"▁해서\", \"▁하나의\", \"▁교향곡\", \"을\", \"▁쓰\", \"려는\", \"▁뜻을\", \"▁갖는다\", \".\", \"▁이\", \"▁시기\", \"▁바그너\", \"는\", \"▁1838\", \"년에\", \"▁빛\", \"▁독\", \"촉\", \"으로\", \"▁산\", \"전\", \"수\", \"전을\", \"▁다\", \"▁\", \"걲\", \"은\", \"▁상황이\", \"라\", \"▁좌절\", \"과\", \"▁실망\", \"에\", \"▁가득\", \"했으며\", \"▁메\", \"피스\", \"토\", \"펠\", \"레스\", \"를\", \"▁만나는\", \"▁\", \"파우스트\", \"의\", \"▁심\", \"경에\", \"▁공감\", \"했다고\", \"▁한다\", \".\", \"▁또한\", \"▁파리에서\", \"▁아브\", \"네\", \"크의\", \"▁지휘\", \"로\", \"▁파리\", \"▁음악원\", \"▁관현악단\", \"이\", \"▁연주하는\", \"▁베토벤\", \"의\", \"▁교향곡\", \"▁9\", \"번을\", \"▁듣고\", \"▁깊은\", \"▁감\", \"명을\", \"▁받았는데\", \",\", \"▁이것이\", \"▁이듬해\", \"▁1\", \"월에\", \"▁\", \"파우스트\", \"의\", \"▁서\", \"곡으로\", \"▁쓰여진\", \"▁이\", \"▁작품에\", \"▁조금\", \"이라도\", \"▁영향을\", \"▁끼\", \"쳤\", \"으리라\", \"는\", \"▁것은\", \"▁의심\", \"할\", \"▁여지가\", \"▁없다\", \".\", \"▁여기\", \"의\", \"▁라\", \"단\", \"조\", \"▁조성\", \"의\", \"▁경우에도\", \"▁그의\", \"▁전기\", \"에\", \"▁적혀\", \"▁있는\", \"▁것처럼\", \"▁단순한\", \"▁정신적\", \"▁피로\", \"나\", \"▁실\", \"의\", \"가\", \"▁반영\", \"된\", \"▁것이\", \"▁아니라\", \"▁베토벤\", \"의\", \"▁합창\", \"교\", \"향\", \"곡\", \"▁조성\", \"의\", \"▁영향을\", \"▁받은\", \"▁것을\", \"▁볼\", \"▁수\", \"▁있다\", \".\", \"▁그렇게\", \"▁교향곡\", \"▁작곡\", \"을\", \"▁1839\", \"년부터\", \"▁40\", \"년에\", \"▁걸쳐\", \"▁파리에서\", \"▁착수\", \"했으나\", \"▁1\", \"악장\", \"을\", \"▁쓴\", \"▁뒤에\", \"▁중단\", \"했다\", \".\", \"▁또한\", \"▁작품의\", \"▁완성\", \"과\", \"▁동시에\", \"▁그는\", \"▁이\", \"▁서\", \"곡\", \"(1\", \"악장\", \")\", \"을\", \"▁파리\", \"▁음악원\", \"의\", \"▁연주회\", \"에서\", \"▁연주\", \"할\", \"▁파트\", \"보\", \"까지\", \"▁준비\", \"하였으나\", \",\", \"▁실제로는\", \"▁이루어지지\", \"는\", \"▁않았다\", \".\", \"▁결국\", \"▁초연\", \"은\", \"▁4\", \"년\", \"▁반\", \"이\", \"▁지난\", \"▁후에\", \"▁드레스덴\", \"에서\", \"▁연주\", \"되었고\", \"▁재\", \"연\", \"도\", \"▁이루어졌\", \"지만\", \",\", \"▁이후에\", \"▁그대로\", \"▁방치\", \"되고\", \"▁말았다\", \".\", \"▁그\", \"▁사이에\", \"▁그는\", \"▁리\", \"엔\", \"치\", \"와\", \"▁방\", \"황\", \"하는\", \"▁네덜란드\", \"인\", \"을\", \"▁완성\", \"하고\", \"▁탄\", \"호\", \"이\", \"저\", \"에도\", \"▁착수\", \"하는\", \"▁등\", \"▁분\", \"주\", \"한\", \"▁시간을\", \"▁보\", \"냈는데\", \",\", \"▁그런\", \"▁바쁜\", \"▁생활\", \"이\", \"▁이\", \"▁곡을\", \"▁잊\", \"게\", \"▁한\", \"▁것이\", \"▁아닌\", \"가\", \"▁하는\", \"▁의견도\", \"▁있다\", \".\"], \"answer\": \"파우스트\", \"token_start\": 6, \"token_end\": 7}\n",
      "{\"qa_id\": \"6566518-0-1\", \"title\": \"파우스트_서곡\", \"question\": [\"▁\", \"파우스트\", \"▁서\", \"곡\", \"의\", \"▁라\", \"단\", \"조\", \"▁조성\", \"이\", \"▁영향을\", \"▁받은\", \"▁베토벤\", \"의\", \"▁곡은\", \"?\"], \"context\": [\"▁1839\", \"년\", \"▁바그너\", \"는\", \"▁괴테\", \"의\", \"▁\", \"파우스트\", \"을\", \"▁처음\", \"▁읽고\", \"▁그\", \"▁내용에\", \"▁마음이\", \"▁끌려\", \"▁이를\", \"▁소재로\", \"▁해서\", \"▁하나의\", \"▁교향곡\", \"을\", \"▁쓰\", \"려는\", \"▁뜻을\", \"▁갖는다\", \".\", \"▁이\", \"▁시기\", \"▁바그너\", \"는\", \"▁1838\", \"년에\", \"▁빛\", \"▁독\", \"촉\", \"으로\", \"▁산\", \"전\", \"수\", \"전을\", \"▁다\", \"▁\", \"걲\", \"은\", \"▁상황이\", \"라\", \"▁좌절\", \"과\", \"▁실망\", \"에\", \"▁가득\", \"했으며\", \"▁메\", \"피스\", \"토\", \"펠\", \"레스\", \"를\", \"▁만나는\", \"▁\", \"파우스트\", \"의\", \"▁심\", \"경에\", \"▁공감\", \"했다고\", \"▁한다\", \".\", \"▁또한\", \"▁파리에서\", \"▁아브\", \"네\", \"크의\", \"▁지휘\", \"로\", \"▁파리\", \"▁음악원\", \"▁관현악단\", \"이\", \"▁연주하는\", \"▁베토벤\", \"의\", \"▁교향곡\", \"▁9\", \"번을\", \"▁듣고\", \"▁깊은\", \"▁감\", \"명을\", \"▁받았는데\", \",\", \"▁이것이\", \"▁이듬해\", \"▁1\", \"월에\", \"▁\", \"파우스트\", \"의\", \"▁서\", \"곡으로\", \"▁쓰여진\", \"▁이\", \"▁작품에\", \"▁조금\", \"이라도\", \"▁영향을\", \"▁끼\", \"쳤\", \"으리라\", \"는\", \"▁것은\", \"▁의심\", \"할\", \"▁여지가\", \"▁없다\", \".\", \"▁여기\", \"의\", \"▁라\", \"단\", \"조\", \"▁조성\", \"의\", \"▁경우에도\", \"▁그의\", \"▁전기\", \"에\", \"▁적혀\", \"▁있는\", \"▁것처럼\", \"▁단순한\", \"▁정신적\", \"▁피로\", \"나\", \"▁실\", \"의\", \"가\", \"▁반영\", \"된\", \"▁것이\", \"▁아니라\", \"▁베토벤\", \"의\", \"▁합창\", \"교\", \"향\", \"곡\", \"▁조성\", \"의\", \"▁영향을\", \"▁받은\", \"▁것을\", \"▁볼\", \"▁수\", \"▁있다\", \".\", \"▁그렇게\", \"▁교향곡\", \"▁작곡\", \"을\", \"▁1839\", \"년부터\", \"▁40\", \"년에\", \"▁걸쳐\", \"▁파리에서\", \"▁착수\", \"했으나\", \"▁1\", \"악장\", \"을\", \"▁쓴\", \"▁뒤에\", \"▁중단\", \"했다\", \".\", \"▁또한\", \"▁작품의\", \"▁완성\", \"과\", \"▁동시에\", \"▁그는\", \"▁이\", \"▁서\", \"곡\", \"(1\", \"악장\", \")\", \"을\", \"▁파리\", \"▁음악원\", \"의\", \"▁연주회\", \"에서\", \"▁연주\", \"할\", \"▁파트\", \"보\", \"까지\", \"▁준비\", \"하였으나\", \",\", \"▁실제로는\", \"▁이루어지지\", \"는\", \"▁않았다\", \".\", \"▁결국\", \"▁초연\", \"은\", \"▁4\", \"년\", \"▁반\", \"이\", \"▁지난\", \"▁후에\", \"▁드레스덴\", \"에서\", \"▁연주\", \"되었고\", \"▁재\", \"연\", \"도\", \"▁이루어졌\", \"지만\", \",\", \"▁이후에\", \"▁그대로\", \"▁방치\", \"되고\", \"▁말았다\", \".\", \"▁그\", \"▁사이에\", \"▁그는\", \"▁리\", \"엔\", \"치\", \"와\", \"▁방\", \"황\", \"하는\", \"▁네덜란드\", \"인\", \"을\", \"▁완성\", \"하고\", \"▁탄\", \"호\", \"이\", \"저\", \"에도\", \"▁착수\", \"하는\", \"▁등\", \"▁분\", \"주\", \"한\", \"▁시간을\", \"▁보\", \"냈는데\", \",\", \"▁그런\", \"▁바쁜\", \"▁생활\", \"이\", \"▁이\", \"▁곡을\", \"▁잊\", \"게\", \"▁한\", \"▁것이\", \"▁아닌\", \"가\", \"▁하는\", \"▁의견도\", \"▁있다\", \".\"], \"answer\": \"합창교향곡\", \"token_start\": 143, \"token_end\": 146}\n",
      "{\"qa_id\": \"5917067-0-0\", \"title\": \"파우스트_서곡\", \"question\": [\"▁바그너\", \"가\", \"▁\", \"파우스트\", \"를\", \"▁처음으로\", \"▁읽\", \"은\", \"▁\", \"년\", \"도\", \"는\", \"?\"], \"context\": [\"▁1839\", \"년\", \"▁바그너\", \"는\", \"▁괴테\", \"의\", \"▁\", \"파우스트\", \"을\", \"▁처음\", \"▁읽고\", \"▁그\", \"▁내용에\", \"▁마음이\", \"▁끌려\", \"▁이를\", \"▁소재로\", \"▁해서\", \"▁하나의\", \"▁교향곡\", \"을\", \"▁쓰\", \"려는\", \"▁뜻을\", \"▁갖는다\", \".\", \"▁이\", \"▁시기\", \"▁바그너\", \"는\", \"▁1838\", \"년에\", \"▁빛\", \"▁독\", \"촉\", \"으로\", \"▁산\", \"전\", \"수\", \"전을\", \"▁다\", \"▁\", \"걲\", \"은\", \"▁상황이\", \"라\", \"▁좌절\", \"과\", \"▁실망\", \"에\", \"▁가득\", \"했으며\", \"▁메\", \"피스\", \"토\", \"펠\", \"레스\", \"를\", \"▁만나는\", \"▁\", \"파우스트\", \"의\", \"▁심\", \"경에\", \"▁공감\", \"했다고\", \"▁한다\", \".\", \"▁또한\", \"▁파리에서\", \"▁아브\", \"네\", \"크의\", \"▁지휘\", \"로\", \"▁파리\", \"▁음악원\", \"▁관현악단\", \"이\", \"▁연주하는\", \"▁베토벤\", \"의\", \"▁교향곡\", \"▁9\", \"번을\", \"▁듣고\", \"▁깊은\", \"▁감\", \"명을\", \"▁받았는데\", \",\", \"▁이것이\", \"▁이듬해\", \"▁1\", \"월에\", \"▁\", \"파우스트\", \"의\", \"▁서\", \"곡으로\", \"▁쓰여진\", \"▁이\", \"▁작품에\", \"▁조금\", \"이라도\", \"▁영향을\", \"▁끼\", \"쳤\", \"으리라\", \"는\", \"▁것은\", \"▁의심\", \"할\", \"▁여지가\", \"▁없다\", \".\", \"▁여기\", \"의\", \"▁라\", \"단\", \"조\", \"▁조성\", \"의\", \"▁경우에도\", \"▁그의\", \"▁전기\", \"에\", \"▁적혀\", \"▁있는\", \"▁것처럼\", \"▁단순한\", \"▁정신적\", \"▁피로\", \"나\", \"▁실\", \"의\", \"가\", \"▁반영\", \"된\", \"▁것이\", \"▁아니라\", \"▁베토벤\", \"의\", \"▁합창\", \"교\", \"향\", \"곡\", \"▁조성\", \"의\", \"▁영향을\", \"▁받은\", \"▁것을\", \"▁볼\", \"▁수\", \"▁있다\", \".\", \"▁그렇게\", \"▁교향곡\", \"▁작곡\", \"을\", \"▁1839\", \"년부터\", \"▁40\", \"년에\", \"▁걸쳐\", \"▁파리에서\", \"▁착수\", \"했으나\", \"▁1\", \"악장\", \"을\", \"▁쓴\", \"▁뒤에\", \"▁중단\", \"했다\", \".\", \"▁또한\", \"▁작품의\", \"▁완성\", \"과\", \"▁동시에\", \"▁그는\", \"▁이\", \"▁서\", \"곡\", \"(1\", \"악장\", \")\", \"을\", \"▁파리\", \"▁음악원\", \"의\", \"▁연주회\", \"에서\", \"▁연주\", \"할\", \"▁파트\", \"보\", \"까지\", \"▁준비\", \"하였으나\", \",\", \"▁실제로는\", \"▁이루어지지\", \"는\", \"▁않았다\", \".\", \"▁결국\", \"▁초연\", \"은\", \"▁4\", \"년\", \"▁반\", \"이\", \"▁지난\", \"▁후에\", \"▁드레스덴\", \"에서\", \"▁연주\", \"되었고\", \"▁재\", \"연\", \"도\", \"▁이루어졌\", \"지만\", \",\", \"▁이후에\", \"▁그대로\", \"▁방치\", \"되고\", \"▁말았다\", \".\", \"▁그\", \"▁사이에\", \"▁그는\", \"▁리\", \"엔\", \"치\", \"와\", \"▁방\", \"황\", \"하는\", \"▁네덜란드\", \"인\", \"을\", \"▁완성\", \"하고\", \"▁탄\", \"호\", \"이\", \"저\", \"에도\", \"▁착수\", \"하는\", \"▁등\", \"▁분\", \"주\", \"한\", \"▁시간을\", \"▁보\", \"냈는데\", \",\", \"▁그런\", \"▁바쁜\", \"▁생활\", \"이\", \"▁이\", \"▁곡을\", \"▁잊\", \"게\", \"▁한\", \"▁것이\", \"▁아닌\", \"가\", \"▁하는\", \"▁의견도\", \"▁있다\", \".\"], \"answer\": \"1839\", \"token_start\": 0, \"token_end\": 0}\n",
      "{\"qa_id\": \"5917067-0-1\", \"title\": \"파우스트_서곡\", \"question\": [\"▁바그너\", \"가\", \"▁처음\", \"▁교향곡\", \"▁작곡\", \"을\", \"▁한\", \"▁장소\", \"는\", \"?\"], \"context\": [\"▁1839\", \"년\", \"▁바그너\", \"는\", \"▁괴테\", \"의\", \"▁\", \"파우스트\", \"을\", \"▁처음\", \"▁읽고\", \"▁그\", \"▁내용에\", \"▁마음이\", \"▁끌려\", \"▁이를\", \"▁소재로\", \"▁해서\", \"▁하나의\", \"▁교향곡\", \"을\", \"▁쓰\", \"려는\", \"▁뜻을\", \"▁갖는다\", \".\", \"▁이\", \"▁시기\", \"▁바그너\", \"는\", \"▁1838\", \"년에\", \"▁빛\", \"▁독\", \"촉\", \"으로\", \"▁산\", \"전\", \"수\", \"전을\", \"▁다\", \"▁\", \"걲\", \"은\", \"▁상황이\", \"라\", \"▁좌절\", \"과\", \"▁실망\", \"에\", \"▁가득\", \"했으며\", \"▁메\", \"피스\", \"토\", \"펠\", \"레스\", \"를\", \"▁만나는\", \"▁\", \"파우스트\", \"의\", \"▁심\", \"경에\", \"▁공감\", \"했다고\", \"▁한다\", \".\", \"▁또한\", \"▁파리에서\", \"▁아브\", \"네\", \"크의\", \"▁지휘\", \"로\", \"▁파리\", \"▁음악원\", \"▁관현악단\", \"이\", \"▁연주하는\", \"▁베토벤\", \"의\", \"▁교향곡\", \"▁9\", \"번을\", \"▁듣고\", \"▁깊은\", \"▁감\", \"명을\", \"▁받았는데\", \",\", \"▁이것이\", \"▁이듬해\", \"▁1\", \"월에\", \"▁\", \"파우스트\", \"의\", \"▁서\", \"곡으로\", \"▁쓰여진\", \"▁이\", \"▁작품에\", \"▁조금\", \"이라도\", \"▁영향을\", \"▁끼\", \"쳤\", \"으리라\", \"는\", \"▁것은\", \"▁의심\", \"할\", \"▁여지가\", \"▁없다\", \".\", \"▁여기\", \"의\", \"▁라\", \"단\", \"조\", \"▁조성\", \"의\", \"▁경우에도\", \"▁그의\", \"▁전기\", \"에\", \"▁적혀\", \"▁있는\", \"▁것처럼\", \"▁단순한\", \"▁정신적\", \"▁피로\", \"나\", \"▁실\", \"의\", \"가\", \"▁반영\", \"된\", \"▁것이\", \"▁아니라\", \"▁베토벤\", \"의\", \"▁합창\", \"교\", \"향\", \"곡\", \"▁조성\", \"의\", \"▁영향을\", \"▁받은\", \"▁것을\", \"▁볼\", \"▁수\", \"▁있다\", \".\", \"▁그렇게\", \"▁교향곡\", \"▁작곡\", \"을\", \"▁1839\", \"년부터\", \"▁40\", \"년에\", \"▁걸쳐\", \"▁파리에서\", \"▁착수\", \"했으나\", \"▁1\", \"악장\", \"을\", \"▁쓴\", \"▁뒤에\", \"▁중단\", \"했다\", \".\", \"▁또한\", \"▁작품의\", \"▁완성\", \"과\", \"▁동시에\", \"▁그는\", \"▁이\", \"▁서\", \"곡\", \"(1\", \"악장\", \")\", \"을\", \"▁파리\", \"▁음악원\", \"의\", \"▁연주회\", \"에서\", \"▁연주\", \"할\", \"▁파트\", \"보\", \"까지\", \"▁준비\", \"하였으나\", \",\", \"▁실제로는\", \"▁이루어지지\", \"는\", \"▁않았다\", \".\", \"▁결국\", \"▁초연\", \"은\", \"▁4\", \"년\", \"▁반\", \"이\", \"▁지난\", \"▁후에\", \"▁드레스덴\", \"에서\", \"▁연주\", \"되었고\", \"▁재\", \"연\", \"도\", \"▁이루어졌\", \"지만\", \",\", \"▁이후에\", \"▁그대로\", \"▁방치\", \"되고\", \"▁말았다\", \".\", \"▁그\", \"▁사이에\", \"▁그는\", \"▁리\", \"엔\", \"치\", \"와\", \"▁방\", \"황\", \"하는\", \"▁네덜란드\", \"인\", \"을\", \"▁완성\", \"하고\", \"▁탄\", \"호\", \"이\", \"저\", \"에도\", \"▁착수\", \"하는\", \"▁등\", \"▁분\", \"주\", \"한\", \"▁시간을\", \"▁보\", \"냈는데\", \",\", \"▁그런\", \"▁바쁜\", \"▁생활\", \"이\", \"▁이\", \"▁곡을\", \"▁잊\", \"게\", \"▁한\", \"▁것이\", \"▁아닌\", \"가\", \"▁하는\", \"▁의견도\", \"▁있다\", \".\"], \"answer\": \"파리\", \"token_start\": 165, \"token_end\": 165}\n",
      "{\"qa_id\": \"5917067-0-2\", \"title\": \"파우스트_서곡\", \"question\": [\"▁바그너\", \"의\", \"▁1\", \"악장\", \"의\", \"▁초연\", \"은\", \"▁어디서\", \"▁연주\", \"되었\", \"는\", \"가\", \"?\"], \"context\": [\"▁1839\", \"년\", \"▁바그너\", \"는\", \"▁괴테\", \"의\", \"▁\", \"파우스트\", \"을\", \"▁처음\", \"▁읽고\", \"▁그\", \"▁내용에\", \"▁마음이\", \"▁끌려\", \"▁이를\", \"▁소재로\", \"▁해서\", \"▁하나의\", \"▁교향곡\", \"을\", \"▁쓰\", \"려는\", \"▁뜻을\", \"▁갖는다\", \".\", \"▁이\", \"▁시기\", \"▁바그너\", \"는\", \"▁1838\", \"년에\", \"▁빛\", \"▁독\", \"촉\", \"으로\", \"▁산\", \"전\", \"수\", \"전을\", \"▁다\", \"▁\", \"걲\", \"은\", \"▁상황이\", \"라\", \"▁좌절\", \"과\", \"▁실망\", \"에\", \"▁가득\", \"했으며\", \"▁메\", \"피스\", \"토\", \"펠\", \"레스\", \"를\", \"▁만나는\", \"▁\", \"파우스트\", \"의\", \"▁심\", \"경에\", \"▁공감\", \"했다고\", \"▁한다\", \".\", \"▁또한\", \"▁파리에서\", \"▁아브\", \"네\", \"크의\", \"▁지휘\", \"로\", \"▁파리\", \"▁음악원\", \"▁관현악단\", \"이\", \"▁연주하는\", \"▁베토벤\", \"의\", \"▁교향곡\", \"▁9\", \"번을\", \"▁듣고\", \"▁깊은\", \"▁감\", \"명을\", \"▁받았는데\", \",\", \"▁이것이\", \"▁이듬해\", \"▁1\", \"월에\", \"▁\", \"파우스트\", \"의\", \"▁서\", \"곡으로\", \"▁쓰여진\", \"▁이\", \"▁작품에\", \"▁조금\", \"이라도\", \"▁영향을\", \"▁끼\", \"쳤\", \"으리라\", \"는\", \"▁것은\", \"▁의심\", \"할\", \"▁여지가\", \"▁없다\", \".\", \"▁여기\", \"의\", \"▁라\", \"단\", \"조\", \"▁조성\", \"의\", \"▁경우에도\", \"▁그의\", \"▁전기\", \"에\", \"▁적혀\", \"▁있는\", \"▁것처럼\", \"▁단순한\", \"▁정신적\", \"▁피로\", \"나\", \"▁실\", \"의\", \"가\", \"▁반영\", \"된\", \"▁것이\", \"▁아니라\", \"▁베토벤\", \"의\", \"▁합창\", \"교\", \"향\", \"곡\", \"▁조성\", \"의\", \"▁영향을\", \"▁받은\", \"▁것을\", \"▁볼\", \"▁수\", \"▁있다\", \".\", \"▁그렇게\", \"▁교향곡\", \"▁작곡\", \"을\", \"▁1839\", \"년부터\", \"▁40\", \"년에\", \"▁걸쳐\", \"▁파리에서\", \"▁착수\", \"했으나\", \"▁1\", \"악장\", \"을\", \"▁쓴\", \"▁뒤에\", \"▁중단\", \"했다\", \".\", \"▁또한\", \"▁작품의\", \"▁완성\", \"과\", \"▁동시에\", \"▁그는\", \"▁이\", \"▁서\", \"곡\", \"(1\", \"악장\", \")\", \"을\", \"▁파리\", \"▁음악원\", \"의\", \"▁연주회\", \"에서\", \"▁연주\", \"할\", \"▁파트\", \"보\", \"까지\", \"▁준비\", \"하였으나\", \",\", \"▁실제로는\", \"▁이루어지지\", \"는\", \"▁않았다\", \".\", \"▁결국\", \"▁초연\", \"은\", \"▁4\", \"년\", \"▁반\", \"이\", \"▁지난\", \"▁후에\", \"▁드레스덴\", \"에서\", \"▁연주\", \"되었고\", \"▁재\", \"연\", \"도\", \"▁이루어졌\", \"지만\", \",\", \"▁이후에\", \"▁그대로\", \"▁방치\", \"되고\", \"▁말았다\", \".\", \"▁그\", \"▁사이에\", \"▁그는\", \"▁리\", \"엔\", \"치\", \"와\", \"▁방\", \"황\", \"하는\", \"▁네덜란드\", \"인\", \"을\", \"▁완성\", \"하고\", \"▁탄\", \"호\", \"이\", \"저\", \"에도\", \"▁착수\", \"하는\", \"▁등\", \"▁분\", \"주\", \"한\", \"▁시간을\", \"▁보\", \"냈는데\", \",\", \"▁그런\", \"▁바쁜\", \"▁생활\", \"이\", \"▁이\", \"▁곡을\", \"▁잊\", \"게\", \"▁한\", \"▁것이\", \"▁아닌\", \"가\", \"▁하는\", \"▁의견도\", \"▁있다\", \".\"], \"answer\": \"드레스덴\", \"token_start\": 216, \"token_end\": 216}\n",
      "{\"qa_id\": \"6566495-1-0\", \"title\": \"파우스트_서곡\", \"question\": [\"▁바그너\", \"의\", \"▁작품을\", \"▁시인\", \"의\", \"▁피로\", \"▁쓰여\", \"졌다\", \"고\", \"▁극찬\", \"한\", \"▁것은\", \"▁누구\", \"인\", \"가\", \"?\"], \"context\": [\"▁한편\", \"▁1840\", \"년부터\", \"▁바그너\", \"와\", \"▁알고\", \"▁지내던\", \"▁리스트\", \"가\", \"▁잊\", \"혀\", \"져\", \"▁있던\", \"▁1\", \"악장\", \"을\", \"▁부활\", \"시켜\", \"▁1852\", \"년에\", \"▁바이마르\", \"에서\", \"▁연주\", \"했다\", \".\", \"▁이것을\", \"▁계기로\", \"▁바그너\", \"도\", \"▁이\", \"▁작품에\", \"▁다시\", \"▁관심을\", \"▁갖게\", \"▁되었고\", \",\", \"▁그\", \"▁해\", \"▁9\", \"월에는\", \"▁총\", \"보\", \"의\", \"▁반환\", \"을\", \"▁요구\", \"하여\", \"▁이를\", \"▁서\", \"곡으로\", \"▁간\", \"추\", \"린\", \"▁다음\", \"▁수정\", \"을\", \"▁했고\", \"▁브\", \"라이트\", \"코프\", \"흐\", \"▁&\", \"▁헤르\", \"텔\", \"▁출판사\", \"에서\", \"▁출판\", \"할\", \"▁개정\", \"판\", \"도\", \"▁준비\", \"했다\", \".\", \"▁1853\", \"년\", \"▁5\", \"월에는\", \"▁리스트\", \"가\", \"▁이\", \"▁작품이\", \"▁수정\", \"되었다\", \"는\", \"▁것을\", \"▁인정\", \"했지만\", \",\", \"▁끝내\", \"▁바그너\", \"의\", \"▁출판\", \"▁계획은\", \"▁무산\", \"되고\", \"▁말았다\", \".\", \"▁이후\", \"▁1855\", \"년에\", \"▁리스트\", \"가\", \"▁자신의\", \"▁작품\", \"▁\", \"파우스트\", \"▁교향곡\", \"을\", \"▁거의\", \"▁완성\", \"하여\", \"▁그\", \"▁사실을\", \"▁바그너\", \"에게\", \"▁알\", \"렸고\", \",\", \"▁바그너\", \"는\", \"▁다시\", \"▁개정된\", \"▁총\", \"보를\", \"▁리스트\", \"에게\", \"▁보내고\", \"▁브\", \"라이트\", \"코프\", \"흐\", \"▁&\", \"▁헤르\", \"텔\", \"▁출판사\", \"에는\", \"▁20\", \"루이\", \"의\", \"▁금\", \"을\", \"▁받고\", \"▁팔았다\", \".\", \"▁또한\", \"▁그의\", \"▁작품을\", \"▁“\", \"하나\", \"하나\", \"의\", \"▁음\", \"표\", \"가\", \"▁시인\", \"의\", \"▁피로\", \"▁쓰여\", \"졌다\", \"”\", \"며\", \"▁극찬\", \"했던\", \"▁한스\", \"▁폰\", \"▁\", \"뷜\", \"로\", \"가\", \"▁그것을\", \"▁피아노\", \"▁독주\", \"용으로\", \"▁편곡\", \"했는데\", \",\", \"▁리스트\", \"는\", \"▁그것을\", \"▁약간\", \"▁변형\", \"되었을\", \"▁뿐\", \"이라고\", \"▁지적했다\", \".\", \"▁이\", \"▁서\", \"곡\", \"의\", \"▁총\", \"보\", \"▁첫\", \"머리\", \"에는\", \"▁\", \"파우스트\", \"▁1\", \"부의\", \"▁내용\", \"▁중\", \"▁한\", \"▁구절\", \"을\", \"▁인용\", \"하고\", \"▁있다\", \".\"], \"answer\": \"한스 폰 뷜로\", \"token_start\": 164, \"token_end\": 168}\n",
      "{\"qa_id\": \"6566495-1-1\", \"title\": \"파우스트_서곡\", \"question\": [\"▁잊\", \"혀\", \"져\", \"▁있는\", \"▁\", \"파우스트\", \"▁서\", \"곡\", \"▁1\", \"악장\", \"을\", \"▁부활\", \"시킨\", \"▁것은\", \"▁누구\", \"인\", \"가\", \"?\"], \"context\": [\"▁한편\", \"▁1840\", \"년부터\", \"▁바그너\", \"와\", \"▁알고\", \"▁지내던\", \"▁리스트\", \"가\", \"▁잊\", \"혀\", \"져\", \"▁있던\", \"▁1\", \"악장\", \"을\", \"▁부활\", \"시켜\", \"▁1852\", \"년에\", \"▁바이마르\", \"에서\", \"▁연주\", \"했다\", \".\", \"▁이것을\", \"▁계기로\", \"▁바그너\", \"도\", \"▁이\", \"▁작품에\", \"▁다시\", \"▁관심을\", \"▁갖게\", \"▁되었고\", \",\", \"▁그\", \"▁해\", \"▁9\", \"월에는\", \"▁총\", \"보\", \"의\", \"▁반환\", \"을\", \"▁요구\", \"하여\", \"▁이를\", \"▁서\", \"곡으로\", \"▁간\", \"추\", \"린\", \"▁다음\", \"▁수정\", \"을\", \"▁했고\", \"▁브\", \"라이트\", \"코프\", \"흐\", \"▁&\", \"▁헤르\", \"텔\", \"▁출판사\", \"에서\", \"▁출판\", \"할\", \"▁개정\", \"판\", \"도\", \"▁준비\", \"했다\", \".\", \"▁1853\", \"년\", \"▁5\", \"월에는\", \"▁리스트\", \"가\", \"▁이\", \"▁작품이\", \"▁수정\", \"되었다\", \"는\", \"▁것을\", \"▁인정\", \"했지만\", \",\", \"▁끝내\", \"▁바그너\", \"의\", \"▁출판\", \"▁계획은\", \"▁무산\", \"되고\", \"▁말았다\", \".\", \"▁이후\", \"▁1855\", \"년에\", \"▁리스트\", \"가\", \"▁자신의\", \"▁작품\", \"▁\", \"파우스트\", \"▁교향곡\", \"을\", \"▁거의\", \"▁완성\", \"하여\", \"▁그\", \"▁사실을\", \"▁바그너\", \"에게\", \"▁알\", \"렸고\", \",\", \"▁바그너\", \"는\", \"▁다시\", \"▁개정된\", \"▁총\", \"보를\", \"▁리스트\", \"에게\", \"▁보내고\", \"▁브\", \"라이트\", \"코프\", \"흐\", \"▁&\", \"▁헤르\", \"텔\", \"▁출판사\", \"에는\", \"▁20\", \"루이\", \"의\", \"▁금\", \"을\", \"▁받고\", \"▁팔았다\", \".\", \"▁또한\", \"▁그의\", \"▁작품을\", \"▁“\", \"하나\", \"하나\", \"의\", \"▁음\", \"표\", \"가\", \"▁시인\", \"의\", \"▁피로\", \"▁쓰여\", \"졌다\", \"”\", \"며\", \"▁극찬\", \"했던\", \"▁한스\", \"▁폰\", \"▁\", \"뷜\", \"로\", \"가\", \"▁그것을\", \"▁피아노\", \"▁독주\", \"용으로\", \"▁편곡\", \"했는데\", \",\", \"▁리스트\", \"는\", \"▁그것을\", \"▁약간\", \"▁변형\", \"되었을\", \"▁뿐\", \"이라고\", \"▁지적했다\", \".\", \"▁이\", \"▁서\", \"곡\", \"의\", \"▁총\", \"보\", \"▁첫\", \"머리\", \"에는\", \"▁\", \"파우스트\", \"▁1\", \"부의\", \"▁내용\", \"▁중\", \"▁한\", \"▁구절\", \"을\", \"▁인용\", \"하고\", \"▁있다\", \".\"], \"answer\": \"리스트\", \"token_start\": 7, \"token_end\": 7}\n"
     ]
    }
   ],
   "source": [
    "def print_file(filename, count=10):\n",
    "    \"\"\"\n",
    "    파일 내용 출력\n",
    "    :param filename: 파일 이름\n",
    "    :param count: 출력 라인 수\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if count <= i:\n",
    "                break\n",
    "            print(line.strip())\n",
    "\n",
    "print_file(f\"{data_dir}/korquad_train.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 전처리 5) : 데이터분석 : Question\n",
    "- 이상데이터(abbnormal)유무 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 ['▁바그너', '는', '▁괴테', '의', '▁', '파우스트', '를', '▁읽고', '▁무엇을', '▁쓰고', '자', '▁', '했', '는', '가', '?']\n",
      "168 ['▁바그너', '는', '▁교향곡', '▁작곡', '을', '▁어디', '까지', '▁쓴', '▁뒤에', '▁중단', '했', '는', '가', '?']\n",
      "80 ['▁바그너', '가', '▁', '파우스트', '▁서', '곡을', '▁쓸', '▁때', '▁어떤', '▁곡', '의', '▁영향을', '▁받았', '는', '가', '?']\n",
      "6 ['▁1839', '년', '▁바그너', '가', '▁교향곡', '의', '▁소재로', '▁쓰', '려고', '▁했던', '▁책은', '?']\n",
      "143 ['▁', '파우스트', '▁서', '곡', '의', '▁라', '단', '조', '▁조성', '이', '▁영향을', '▁받은', '▁베토벤', '의', '▁곡은', '?']\n",
      "0 ['▁바그너', '가', '▁', '파우스트', '를', '▁처음으로', '▁읽', '은', '▁', '년', '도', '는', '?']\n",
      "165 ['▁바그너', '가', '▁처음', '▁교향곡', '▁작곡', '을', '▁한', '▁장소', '는', '?']\n",
      "216 ['▁바그너', '의', '▁1', '악장', '의', '▁초연', '은', '▁어디서', '▁연주', '되었', '는', '가', '?']\n",
      "164 ['▁바그너', '의', '▁작품을', '▁시인', '의', '▁피로', '▁쓰여', '졌다', '고', '▁극찬', '한', '▁것은', '▁누구', '인', '가', '?']\n",
      "7 ['▁잊', '혀', '져', '▁있는', '▁', '파우스트', '▁서', '곡', '▁1', '악장', '을', '▁부활', '시킨', '▁것은', '▁누구', '인', '가', '?']\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "contexts = []\n",
    "token_starts = []\n",
    "with open(f\"{data_dir}/korquad_train.json\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        questions.append(data[\"question\"])\n",
    "        contexts.append(data[\"context\"])\n",
    "        token_starts.append(data[\"token_start\"])\n",
    "        if i < 10:\n",
    "            print(data[\"token_start\"], data[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 14, 16, 12, 16, 13, 10, 13, 16, 18]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token count\n",
    "train_question_counts = [len(question) for question in questions]\n",
    "train_question_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(train_question_counts, bins=100, range=[0, 100], facecolor='b', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Count of question')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of question')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of question')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 길이 최대:      58\n",
      "question 길이 최소:       3\n",
      "question 길이 평균:      15.25\n",
      "question 길이 표준편차:    5.50\n",
      "question 25/100분위:    11.00\n",
      "question 50/100분위:    14.00\n",
      "question 75/100분위:    18.00\n",
      "question IQR:           7.00\n",
      "question MAX/100분위:   28.50\n"
     ]
    }
   ],
   "source": [
    "# 데이터 길이\n",
    "print(f\"question 길이 최대:    {np.max(train_question_counts):4d}\")\n",
    "print(f\"question 길이 최소:    {np.min(train_question_counts):4d}\")\n",
    "print(f\"question 길이 평균:    {np.mean(train_question_counts):7.2f}\")\n",
    "print(f\"question 길이 표준편차: {np.std(train_question_counts):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(train_question_counts, 25)\n",
    "percentile50 = np.percentile(train_question_counts, 50)\n",
    "percentile75 = np.percentile(train_question_counts, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"question 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"question 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"question 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"question IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"question MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(train_question_counts, labels=['token counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 전처리 6) : 데이터 분석 : Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[278, 278, 278, 278, 278, 278, 278, 278, 209, 209]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token count\n",
    "train_context_counts = [len(context) for context in contexts]\n",
    "train_context_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(train_context_counts, bins=900, range=[100, 1000], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Count of context')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of context')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of context')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context 길이 최대:    4816\n",
      "context 길이 최소:     108\n",
      "context 길이 평균:     222.84\n",
      "context 길이 표준편차:   97.68\n",
      "context 25/100분위:   169.00\n",
      "context 50/100분위:   199.00\n",
      "context 75/100분위:   248.00\n",
      "context IQR:          79.00\n",
      "context MAX/100분위:  366.50\n"
     ]
    }
   ],
   "source": [
    "# 데이터 길이\n",
    "print(f\"context 길이 최대:    {np.max(train_context_counts):4d}\")\n",
    "print(f\"context 길이 최소:    {np.min(train_context_counts):4d}\")\n",
    "print(f\"context 길이 평균:    {np.mean(train_context_counts):7.2f}\")\n",
    "print(f\"context 길이 표준편차: {np.std(train_context_counts):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(train_context_counts, 25)\n",
    "percentile50 = np.percentile(train_context_counts, 50)\n",
    "percentile75 = np.percentile(train_context_counts, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"context 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"context 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"context 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"context IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"context MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(train_context_counts, labels=['token counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 전처리 7) : 데이터분석 : Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 168, 80, 6, 143, 0, 165, 216, 164, 7]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token count\n",
    "train_answer_starts = token_starts\n",
    "train_answer_starts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(train_answer_starts, bins=500, range=[0, 500], facecolor='g', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Count of answer')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of answer')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of answer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer 위치 최대:    1124\n",
      "answer 위치 최소:       0\n",
      "answer 위치 평균:      89.01\n",
      "answer 위치 표준편차:   78.21\n",
      "answer 25/100분위:    25.00\n",
      "answer 50/100분위:    74.00\n",
      "answer 75/100분위:   134.00\n",
      "answer IQR:         109.00\n",
      "answer MAX/100분위:  297.50\n"
     ]
    }
   ],
   "source": [
    "# 데이터 길이\n",
    "print(f\"answer 위치 최대:    {np.max(train_answer_starts):4d}\")\n",
    "print(f\"answer 위치 최소:    {np.min(train_answer_starts):4d}\")\n",
    "print(f\"answer 위치 평균:    {np.mean(train_answer_starts):7.2f}\")\n",
    "print(f\"answer 위치 표준편차: {np.std(train_answer_starts):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(train_answer_starts, 25)\n",
    "percentile50 = np.percentile(train_answer_starts, 50)\n",
    "percentile75 = np.percentile(train_answer_starts, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"answer 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"answer 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"answer 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"answer IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"answer MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(train_answer_starts, labels=['token counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 전처리 9) : 데이터로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = os.path.join(data_dir, \"korquad_train.json\")\n",
    "dev_json = os.path.join(data_dir, \"korquad_dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_seq_length': 384, 'max_query_length': 64}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "\n",
    "args = Config({\n",
    "    'max_seq_length': 384,\n",
    "    'max_query_length': 64,\n",
    "})\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 데이터셋 파일을 메모리에 로딩하는 함수\n",
    "def load_data(args, filename):\n",
    "    inputs, segments, labels_start, labels_end = [], [], [], []\n",
    "\n",
    "    n_discard = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, desc=f\"Loading ...\")):\n",
    "            data = json.loads(line)\n",
    "            token_start = data.get(\"token_start\")\n",
    "            token_end = data.get(\"token_end\")\n",
    "            question = data[\"question\"][:args.max_query_length]\n",
    "            context = data[\"context\"]\n",
    "            answer_tokens = \" \".join(context[token_start:token_end + 1])\n",
    "            context_len = args.max_seq_length - len(question) - 3\n",
    "\n",
    "            if token_end >= context_len:\n",
    "                # 최대 길이내에 token이 들어가지 않은 경우 처리하지 않음\n",
    "                n_discard += 1\n",
    "                continue\n",
    "            context = context[:context_len]\n",
    "            assert len(question) + len(context) <= args.max_seq_length - 3\n",
    "\n",
    "            tokens = ['[CLS]'] + question + ['[SEP]'] + context + ['[SEP]']\n",
    "            ids = [vocab.piece_to_id(token) for token in tokens]\n",
    "            ids += [0] * (args.max_seq_length - len(ids))\n",
    "            inputs.append(ids)\n",
    "            segs = [0] * (len(question) + 2) + [1] * (len(context) + 1)\n",
    "            segs += [0] * (args.max_seq_length - len(segs))\n",
    "            segments.append(segs)\n",
    "            token_start += (len(question) + 2)\n",
    "            labels_start.append(token_start)\n",
    "            token_end += (len(question) + 2)\n",
    "            labels_end.append(token_end)\n",
    "    print(f'n_discard: {n_discard}')\n",
    "\n",
    "    return (np.array(inputs), np.array(segments)), (np.array(labels_start), np.array(labels_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e9bc01316c4e3580c05c4c2d75d498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Loading ...', max=1.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_discard: 430\n",
      "train_inputs: (59977, 384)\n",
      "train_inputs: (59977, 384)\n",
      "train_labels: (59977,)\n",
      "train_labels: (59977,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7937006169c545408d2334ab542c47be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Loading ...', max=1.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_discard: 78\n",
      "dev_inputs: (5696, 384)\n",
      "dev_inputs: (5696, 384)\n",
      "dev_labels: (5696,)\n",
      "dev_labels: (5696,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([[    5, 15798,    10, ...,     0,     0,     0],\n",
       "         [    5, 15798,    10, ...,     0,     0,     0],\n",
       "         [    5, 15798,    19, ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    5, 21666,    19, ...,     0,     0,     0],\n",
       "         [    5,   964, 16865, ...,     0,     0,     0],\n",
       "         [    5,   365,    15, ...,     0,     0,     0]]),\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]])),\n",
       " (array([ 37, 184,  98, ...,  74, 190,  35]),\n",
       "  array([ 37, 185, 102, ...,  75, 191,  44])))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data load\n",
    "train_inputs, train_labels = load_data(args, train_json)\n",
    "print(f\"train_inputs: {train_inputs[0].shape}\")\n",
    "print(f\"train_inputs: {train_inputs[1].shape}\")\n",
    "print(f\"train_labels: {train_labels[0].shape}\")\n",
    "print(f\"train_labels: {train_labels[1].shape}\")\n",
    "\n",
    "# dev data load\n",
    "dev_inputs, dev_labels = load_data(args, dev_json)\n",
    "print(f\"dev_inputs: {dev_inputs[0].shape}\")\n",
    "print(f\"dev_inputs: {dev_inputs[1].shape}\")\n",
    "print(f\"dev_labels: {dev_labels[0].shape}\")\n",
    "print(f\"dev_labels: {dev_labels[1].shape}\")\n",
    "\n",
    "train_inputs[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    5, 15798,    10, 28935,     9,    11, 29566,    20, 14604,\n",
       "       20424,  3904,    70,    11,  4648,    10,    19,  1910,     4,\n",
       "       22070,    15, 15798,    10, 28935,     9,    11, 29566,    16,\n",
       "         626, 14604,    38, 14028, 11773, 13829,   384,  8376,  3021,\n",
       "        1239,  6874,    16,  1687,  5958,  2694,  5061,     7,    30,\n",
       "        1613, 15798,    10, 28065,    75,  4415,  1816,  4978,    27,\n",
       "         347,   145,   107,  2703,   263,    11,     1,    18,  5853,\n",
       "          99,  9677,    24, 11969,    13,  7595,   437,  1019,  5907,\n",
       "         257,  3794,  1972,    20, 11278,    11, 29566,     9,   612,\n",
       "       12631, 13214,  1732,    76,     7,   110,  8802, 17581,   354,\n",
       "        9648,  2060,    21,  1682, 22110, 18164,    17, 21076, 14980,\n",
       "           9,  6874,    81, 11325,  4239,  3597,  1010,  1035, 17670,\n",
       "           8,  2447,  1306,    35,   443,    11, 29566,     9,   315,\n",
       "       12729, 14457,    30,  7938,  3742, 10766,   634,  9971, 17590,\n",
       "       19424,    10,   285,  4080,    61, 17573,   483,     7,  7588,\n",
       "           9,   473,   338,   147,  1924,     9, 11016,   136,  1034,\n",
       "          13, 11672,    40,  3436,  5217,  7898, 11684,    57,   830,\n",
       "           9,    19,  3319,    86,   220,   464, 14980,     9, 20515,\n",
       "         412,   991,   684,  1924,     9,   634,   920,   144,   430,\n",
       "          34,    25,     7,  4210,  6874,  2150,    16, 22070,   298,\n",
       "        1159,    75,  1098,  8802,  7490,   805,    35, 18678,    16,\n",
       "        1657,  1970,  2272,    53,     7,   110,  6559,  2178,    24,\n",
       "         756,    82,    30,   315,   684,  3772, 18678,    12,    16,\n",
       "        1682, 22110,     9, 22469,    22,  1757,    61,  8817,   194,\n",
       "         164,  1693,   749,     8,  6739, 12202,    10,   494,     7,\n",
       "         502, 12181,    18,    46,    15,   374,    17,  1680,   708,\n",
       "       26344,    22,  1757,   432,   465,   351,    32, 18563,   710,\n",
       "           8,  2585,  1384, 16071,   265,  3360,     7,    38,   747,\n",
       "          82,   383,   678,   200,    26,   590,  1281,    41,  1172,\n",
       "          31,    16,  2178,    43,  3044,   156,    17,   647,   468,\n",
       "        7490,    41,    84,   758,    92,    33,  3401,   369, 18319,\n",
       "           8,  2582, 29798,  1102,    17,    30,  4573, 11170,   139,\n",
       "          58,   220,   773,    19,   211, 23824,    25,     7,     4,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question과 Context가 포함된 입력데이터 1번째\n",
    "train_inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question을 0으로, Context를 1로 구분해 준 Segment 데이터 1번째\n",
    "train_inputs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 37)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer위치의 시작점과 끝점 라벨 1번째\n",
    "train_labels[0][0], train_labels[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT 모델 사용 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유틸리티 함수들\n",
    "\n",
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask\n",
    "\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1 + K.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))\n",
    "\n",
    "\n",
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer\n",
    "\n",
    "\n",
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode == \"embedding\" 일 경우 Token Embedding Layer 로 사용되는 layer 클래스입니다. \n",
    "\n",
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shared Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Positional Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: positional embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionalEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, enc_tokens, segments):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_tokens: encoder tokens\n",
    "        :param segments: token segments\n",
    "        :return logits_cls: CLS 결과 logits\n",
    "        :return logits_lm: LM 결과 logits\n",
    "        \"\"\"\n",
    "        enc_self_mask = get_pad_mask(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = enc_out\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4KorQuAD(tf.keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(name='BERT4KorQuAD')\n",
    "\n",
    "        self.bert = BERT(config)\n",
    "        self.dense = tf.keras.layers.Dense(2)\n",
    "    \n",
    "    def call(self, enc_tokens, segments):\n",
    "        logits_cls, logits_lm = self.bert(enc_tokens, segments)\n",
    "\n",
    "        hidden = self.dense(logits_lm) # (bs, n_seq, 2)\n",
    "        start_logits, end_logits = tf.split(hidden, 2, axis=-1)  # (bs, n_seq, 1), (bs, n_seq, 1)\n",
    "\n",
    "        start_logits = tf.squeeze(start_logits, axis=-1)\n",
    "        start_outputs = tf.keras.layers.Softmax(name=\"start\")(start_logits)\n",
    "\n",
    "        end_logits = tf.squeeze(end_logits, axis=-1)\n",
    "        end_outputs = tf.keras.layers.Softmax(name=\"end\")(end_logits)\n",
    "\n",
    "        return start_outputs, end_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 384,\n",
       " 'n_vocab': 32007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 384, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_batch_size = 32 \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels)).shuffle(10000).batch(bert_batch_size)\n",
    "dev_dataset = tf.data.Dataset.from_tensor_slices((dev_inputs, dev_labels)).batch(bert_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT4KorQuAD(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1. pretrained model 로딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aiffel/aiffel/bert_qna/models\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT4KorQuAD\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (BERT)                  multiple                  10662400  \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             multiple                  514       \n",
      "=================================================================\n",
      "Total params: 10,662,914\n",
      "Trainable params: 10,662,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint_file = os.path.join(model_dir, 'bert_pretrain_32000.hdf5')\n",
    "\n",
    "model = BERT4KorQuAD(config)\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    #  pretrained model 을 로드하기 위해 먼저 모델이 생성되어 있어야 한다.\n",
    "    enc_tokens = np.random.randint(0, len(vocab), (4, 10))\n",
    "    segments = np.random.randint(0, 2, (4, 10))\n",
    "    model(enc_tokens, segments)\n",
    "    \n",
    "    # checkpoint 파일로부터 필요한 layer를 불러온다. \n",
    "    model.load_weights(os.path.join(model_dir, \"bert_pretrain_32000.hdf5\"), by_name=True)\n",
    "\n",
    "    model.summary()\n",
    "else:\n",
    "    print('NO Pretrained Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataset, loss_fn, acc_fn, optimizer):\n",
    "    metric_start_loss = tf.keras.metrics.Mean(name='start_loss')\n",
    "    metric_end_loss = tf.keras.metrics.Mean(name='end_loss')\n",
    "    metric_start_acc = tf.keras.metrics.Mean(name='start_acc')\n",
    "    metric_end_acc = tf.keras.metrics.Mean(name='end_acc')\n",
    "\n",
    "    p_bar = tqdm(dataset)\n",
    "    for batch, ((enc_tokens, segments), (start_labels, end_labels)) in enumerate(p_bar):\n",
    "        with tf.GradientTape() as tape:\n",
    "            start_outputs, end_outputs = model(enc_tokens, segments)\n",
    "\n",
    "            start_loss = loss_fn(start_labels, start_outputs)\n",
    "            end_loss = loss_fn(end_labels, end_outputs)\n",
    "            loss = start_loss + end_loss\n",
    "\n",
    "            start_acc = acc_fn(start_labels, start_outputs)\n",
    "            end_acc = acc_fn(end_labels, end_outputs)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        metric_start_loss(start_loss)\n",
    "        metric_end_loss(end_loss)\n",
    "        metric_start_acc(start_acc)\n",
    "        metric_end_acc(end_acc)\n",
    "        if batch % 10 == 9:\n",
    "            p_bar.set_description(f'loss: {metric_start_loss.result():0.4f}, {metric_end_loss.result():0.4f}, acc: {metric_start_acc.result():0.4f}, {metric_end_acc.result():0.4f}')\n",
    "    p_bar.close()\n",
    "\n",
    "    return metric_start_loss.result(), metric_end_loss.result(), metric_start_acc.result(), metric_end_acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, dataset, loss_fn, acc_fn):\n",
    "    metric_start_loss = tf.keras.metrics.Mean(name='start_loss')\n",
    "    metric_end_loss = tf.keras.metrics.Mean(name='end_loss')\n",
    "    metric_start_acc = tf.keras.metrics.Mean(name='start_acc')\n",
    "    metric_end_acc = tf.keras.metrics.Mean(name='end_acc')\n",
    "\n",
    "    for batch, ((enc_tokens, segments), (start_labels, end_labels)) in enumerate(dataset):\n",
    "        start_outputs, end_outputs = model(enc_tokens, segments)\n",
    "\n",
    "        start_loss = loss_fn(start_labels, start_outputs)\n",
    "        end_loss = loss_fn(end_labels, end_outputs)\n",
    "\n",
    "        start_acc = acc_fn(start_labels, start_outputs)\n",
    "        end_acc = acc_fn(end_labels, end_outputs)\n",
    "\n",
    "        metric_start_loss(start_loss)\n",
    "        metric_end_loss(end_loss)\n",
    "        metric_start_acc(start_acc)\n",
    "        metric_end_acc(end_acc)\n",
    "\n",
    "    return metric_start_loss.result(), metric_end_loss.result(), metric_start_acc.result(), metric_end_acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bcbd36fe124e05bb6fd7514abfc515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 0 >> loss: 3.7019, 4.2537, acc: 0.1254, 0.1103\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af505553d9949c2a9db2b54044512ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 1 >> loss: 3.6464, 4.2597, acc: 0.1420, 0.1169\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f15091dd4245a596cbff4457138844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 2 >> loss: 3.7021, 4.3559, acc: 0.1627, 0.1401\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc60aa074d34b49b4bfe8540455b08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 3 >> loss: 3.7192, 4.1996, acc: 0.1533, 0.1269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f4c65061224267934bc66f3755b453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 4 >> loss: 3.8564, 4.3271, acc: 0.1596, 0.1396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e94b1f48bd448591212f4d575c84ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 5 >> loss: 3.8595, 4.5498, acc: 0.1608, 0.1422\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca085fc94c84f7a947b101ecc975824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 6 >> loss: 4.1992, 4.8876, acc: 0.1573, 0.1413\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b2951f3f8c47f9ab682c84bd8bac9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 7 >> loss: 4.4561, 5.0570, acc: 0.1494, 0.1366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ead1319e1843f986a0cd723258301e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 8 >> loss: 4.9442, 6.0029, acc: 0.1466, 0.1283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aeeedc364e046b4b7683b99cf3081dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 9 >> loss: 5.2315, 5.9182, acc: 0.1438, 0.1250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed57417671b48818bcec1421ca85b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval 10 >> loss: 5.1791, 6.4708, acc: 0.1440, 0.1246\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "acc_fn = tf.keras.metrics.sparse_categorical_accuracy\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "\n",
    "best_acc = .0\n",
    "patience = 0\n",
    "for epoch in range(20):\n",
    "    train_epoch(model, train_dataset, loss_fn, acc_fn, optimizer)\n",
    "    start_loss, end_loss, start_acc, end_acc = eval_epoch(model, dev_dataset, loss_fn, acc_fn)\n",
    "    print(f'eval {epoch} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}')\n",
    "    acc = start_acc + end_acc\n",
    "    if best_acc < acc:\n",
    "        patience = 0\n",
    "        best_acc = acc\n",
    "        model.save_weights(os.path.join(data_dir, \"korquad_bert_none_pretrain.hdf5\"))\n",
    "        print(f'save best model')\n",
    "    else:\n",
    "        patience += 1\n",
    "    if 5 <= patience:\n",
    "        print(f'early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2. pretrained model finetune 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3. Inference 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_predict(model, question, context):\n",
    "    \"\"\"\n",
    "    입력에 대한 답변 생성하는 함수\n",
    "    :param model: model\n",
    "    :param question: 입력 문자열\n",
    "    :param context: 입력 문자열\n",
    "    \"\"\"\n",
    "    q_tokens = vocab.encode_as_pieces(question)[:args.max_query_length]\n",
    "    c_tokens = vocab.encode_as_pieces(context)[:args.max_seq_length - len(q_tokens) - 3]\n",
    "    tokens = ['[CLS]'] + q_tokens + ['[SEP]'] + c_tokens + ['[SEP]']\n",
    "    token_ids = [vocab.piece_to_id(token) for token in tokens]\n",
    "    segments = [0] * (len(q_tokens) + 2) + [1] * (len(c_tokens) + 1)\n",
    "\n",
    "    y_start, y_end = model(np.array([token_ids]), np.array([segments]))\n",
    "    # print(y_start, y_end)\n",
    "    y_start_idx = K.argmax(y_start, axis=-1)[0].numpy()\n",
    "    y_end_idx = K.argmax(y_end, axis=-1)[0].numpy()\n",
    "    answer_tokens = tokens[y_start_idx:y_end_idx + 1]\n",
    "\n",
    "    return vocab.decode_pieces(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "질문 :  임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 연도는?\n",
      "지문 :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "정답 :  1989년\n",
      "예측 :  1989년 \n",
      "\n",
      "3\n",
      "질문 :  임종석을 검거한 장소는 경희대 내 어디인가?\n",
      "지문 :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "정답 :  학생회관 건물 계단\n",
      "예측 :  서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서 \n",
      "\n",
      "7\n",
      "질문 :  정부의 헌법개정안 준비 과정에 대해서 청와대 비서실이 아니라 국무회의 중심으로 이뤄졌어야 했다고 지적한 원로 헌법학자는?\n",
      "지문 :  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의 역할을 벗어난다\"는 의견이 제기되었다. 대표적인 예가 10차 개헌안 발표이다. 원로 헌법학자인 허영 경희대 석좌교수는 정부의 헌법개정안 준비 과정에 대해 \"청와대 비서실이 아닌 국무회의 중심으로 이뤄졌어야 했다\"고 지적했다. '국무회의의 심의를 거쳐야 한다'(제89조)는 헌법 규정에 충실하지 않았다는 것이다. 그러면서 \"법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다\"고 지적했다. 민정수석은 국회의원에 대해 책임지는 법무부 장관도 아니고, 국민에 대해 책임지는 사람도 아니기 때문에 정당성이 없고, 단지 대통령의 신임이 있을 뿐이라는 것이다. 또한 국무총리 선출 방식에 대한 기자의 질문에 \"문 대통령도 취임 전에 국무총리에게 실질적 권한을 주겠다고 했지만 그러지 못하고 있다. 대통령비서실장만도 못한 권한을 행사하고 있다.\"고 답변했다.\n",
      "정답 :  허영\n",
      "예측 :  허영 경희대 석좌교수는 정부의 헌법개정안 준비 과정에 대해 \"청와대 비서실이 아닌 국무회의 중심으로 이뤄졌어야 했다\"고 지적했다. '국무회의의 심의를 거쳐야 한다'(제89조)는 헌법 규정에 충실하지 않았다는 것이다. 그러면서 \"법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다\"고 지적했다. 민정수석은 국회의원에 대해 책임지는 법무부 장관도 아니고, 국민에 대해 책임지는 사람도 아니기 때문에 정당성이 없고, 단지 대통령의 신임이 있을 뿐이라는 것이다. 또한 국무총리 선출 방식에 대한 기자의 질문에 \"문 대통령도 취임 전에 국무총리에게 실질적 권한을 주겠다고 했지만 그러지 못하고 있다. 대통령비서실장만 \n",
      "\n",
      "14\n",
      "질문 :  로널드 레이건 대통령 밑에서 일한 국무 장관은 누구인가?\n",
      "지문 :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "정답 :  알렉산더 메이그스 헤이그 2세\n",
      "예측 :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경 \n",
      "\n",
      "17\n",
      "질문 :  알렉산더 헤이그가 로널드 레이건 대통령 밑에서 맡은 직책은 무엇이었나?\n",
      "지문 :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "정답 :  국무장관\n",
      "예측 :  국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관 \n",
      "\n",
      "22\n",
      "질문 :  헤이그가 공부한 대학교는?\n",
      "지문 :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "정답 :  노터데임 대학교\n",
      "예측 :  노터데임 대학교에서 \n",
      "\n",
      "23\n",
      "질문 :  헤이그의 부인은 누구인가?\n",
      "지문 :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "정답 :  퍼트리샤 앤토이넷 폭스\n",
      "예측 :  기력이 없는 훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스 \n",
      "\n",
      "27\n",
      "질문 :  헤이그가 군에서 퇴역한 해는 언제인가?\n",
      "지문 :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다. 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "정답 :  1979년\n",
      "예측 :  1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다. 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 \n",
      "\n",
      "28\n",
      "질문 :  알렉산더 헤이그를 사성 장군과 육군 부참모로 진급시킨 대통령은 누구인가?\n",
      "지문 :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다. 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "정답 :  닉슨 대통령\n",
      "예측 :  닉슨 대통령이 \n",
      "\n",
      "30\n",
      "질문 :  헤이그가 군에서 퇴역한 년도는 몇년도입니까?\n",
      "지문 :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다. 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "정답 :  1979년\n",
      "예측 :  1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다. 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 \n",
      "\n",
      "32\n",
      "질문 :  헤이그가 군대에서 퇴역한 년도는?\n",
      "지문 :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다. 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "정답 :  1979년\n",
      "예측 :  1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다. 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 \n",
      "\n",
      "34\n",
      "질문 :  알렉산더 헤이그는 레이건의 조언자들을 무엇이라고 묘사하였는가?\n",
      "지문 :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 Worldwide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "정답 :  외교 정책의 아마추어\n",
      "예측 :  \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 Worldwide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장 \n",
      "\n",
      "35\n",
      "질문 :  헤이그가 사적생활을 하다가 정계로 돌아갔던 해는 언제인가?\n",
      "지문 :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 Worldwide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "정답 :  1988년\n",
      "예측 :  1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔다가 1988년 \n",
      "\n",
      "37\n",
      "질문 :  헤이그가 정계로 돌아간 년도는 몇년도입니까?\n",
      "지문 :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 Worldwide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "정답 :  1988년\n",
      "예측 :  1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔다가 1988년 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "질문 :  하나님의 명령에 배를 만들고 가족과 짐승들을 배에 태워 홍수를 피한 사람은 누구인가?\n",
      "지문 :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), 폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "정답 :  노아\n",
      "예측 :  정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍 \n",
      "\n",
      "46\n",
      "질문 :  1규빗을 미터법으로 환산하면 얼마인가?\n",
      "지문 :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), 폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "정답 :  45~46cm\n",
      "예측 :  약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍 \n",
      "\n",
      "49\n",
      "질문 :  노아의 방주를 상징적 의미로 받아들이는 종교는 무엇인가?\n",
      "지문 :  역사학과 과학이 발달하지 않았던 과거 전통 신학계에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아의 방주 자체의 의미는 중요하게 해석된다고 한다\n",
      "정답 :  기독교\n",
      "예측 :  기독교 \n",
      "\n",
      "61\n",
      "질문 :  유사지질학인 홍수지질학이 근원은?\n",
      "지문 :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, 과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, 홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "정답 :  제칠일안식교\n",
      "예측 :  고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교 \n",
      "\n",
      "62\n",
      "질문 :  유사지질학자들이 노아의 홍수를 증명하기 위해 성경 이외에 근거라고 주장한 것들은?\n",
      "지문 :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, 과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, 홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "정답 :  이슬람교 경전이나 길가메쉬 서사시\n",
      "예측 :  메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, 홍수지질학은 \n",
      "\n",
      "63\n",
      "질문 :  노아의 방주가 역사적으로 실재했다는 주장은 무엇이 존재하지 않아 학계로부터 전혀 인정받지 못하고 있는가?\n",
      "지문 :  물론 노아의 방주가 신학과 신앙에서 중요한 영향을 차지하는 것은 사실이나, 현재 노아의 방주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠일안식교를 기반으로 한 홍수지질학적 주장들을을 내어 놓고 있지만, 사실과 다른 근거들을 바탕으로 주장하므로 신뢰하기 힘든 것들이 전부라 할 수 있다. 그러므로 현재 노아의 방주가 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있다. 모든 과학관련 학계에서는 노아의 방주의 구조나 재질등이 실제로 존재할 수 없는 설화속 이야기라는 데에 동의하고 있다.\n",
      "정답 :  증거\n",
      "예측 :  신앙에서 중요한 영향을 차지하는 것은 사실이나, 현재 노아의 방주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠일안식교를 \n",
      "\n",
      "64\n",
      "질문 :  한국에서 홍수지질학적 주장들을 내어 놓고 있는 집단은?\n",
      "지문 :  물론 노아의 방주가 신학과 신앙에서 중요한 영향을 차지하는 것은 사실이나, 현재 노아의 방주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠일안식교를 기반으로 한 홍수지질학적 주장들을을 내어 놓고 있지만, 사실과 다른 근거들을 바탕으로 주장하므로 신뢰하기 힘든 것들이 전부라 할 수 있다. 그러므로 현재 노아의 방주가 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있다. 모든 과학관련 학계에서는 노아의 방주의 구조나 재질등이 실제로 존재할 수 없는 설화속 이야기라는 데에 동의하고 있다.\n",
      "정답 :  한국창조과학회\n",
      "예측 :  방주가 신학과 신앙에서 중요한 영향을 차지하는 것은 사실이나, 현재 노아의 방주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠일안식교를 \n",
      "\n",
      "71\n",
      "질문 :  현재의 생물다양성은 대략 몇 종 인가?\n",
      "지문 :  기독교 성경 내용에는 모든 종들을 방주에 태운다고 이야기하고 있으나, 어류나 수중 생물에 대해서는 언급하지 않았다. 이것을 신학적 의미로만 받아들이면 괜찮은 문제이나, 이 현상이 실제로 일어났다고 가정할 경우,이는 종 간 생존 환경의 차이에 대해서 간과하고 있다. 수중 생물이라 하더라도 종에 따라 생존할 수 있는 환경은 각각 다른 것이며, 40일 이내에 현존하는 가장 높은 산인 에베레스트 산도 잠기게 할 정도의 폭우로 인해 담수와 염수가 급작스럽게 섞일 경우, 급격한 삼투압 변화로 인해 대부분의 수생생물들이 폐사하게 되며, 결과적으로 육지 뿐 아니라 바다와 강의 모든 생태계가 파괴된다. 이후 5천년이라는 지극히 짧은 세월 동안 지구상의 동식물이 모두 페름기 대멸종 또는 K-T 대멸종에 준하는 대량절멸에 가까운 상태에서부터 시작하여 현재의 대략 870만(±120만)종에 달하는 생물다양성을 획득하려면 모든 생물들이 각 세대마다 종분화가 일어나야 할 만큼 엄청난 속도로 진화 및 번식이 (멸종 없이) 이루어져야만 가능한 일이다. (이와 관련하여 창조과학회 측에서는 북극곰의 예시를 통해 가지고 있던 특성이 없어지는 것이 진화가 아니라고 주장하지만, 통상적으로 알려진 바와 같이 생물학에서는 이미 존재하는 특성이 없어지는 현상, 즉 퇴화 역시 진화의 정의에 포함된다.) 즉, 노아의 홍수가 실재하는 사건이었다면 진화적 종분화가 현재까지 알려진 것과 비교할 수 없이 엄청난 속도로 이루어져야만 현재 지구의 생물다양성을 설명할 수 있다. 게다가 이것은 현재의 생물종 멸종 속도를 전혀 고려하지 않았다. 다시 말해, 노아의 홍수가 실재하는 전지구적인 사건이기 위해서는 최소 캄브리아기 대폭발 수준의 폭발적인 진화적 종분화가 1-2억년이 아니라 최대 3-4천년 이내에 이루어졌어야만 현생 지구의 생물다양성에 대한 설명이 가능해진다. 그보다 더 중요한 것은, 각 동물들이 차지하는 영역과 먹이사슬에서의 위치, 375일 동안 먹이도 없이 밀폐된 공간으로 인해 받을 스트레스 등 생태적 지위에 대한 고려가 전혀 없다는 점이다. 또한 바다에서 생존이 불가능한 생물종까지 숫자에 포함되었다는 점에서 논란이 있다.\n",
      "정답 :  870만\n",
      "예측 :  870만(±120만)종에 달하는 생물다양성을 획득하려면 모든 생물들이 각 세대마다 종분화가 일어나야 할 만큼 엄청난 속도로 진화 및 번식이 (멸종 \n",
      "\n",
      "79\n",
      "질문 :  노아의 방주가 안정적인 구조였다고 주장하는 집단은 어디인가?\n",
      "지문 :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "정답 :  창조과학회\n",
      "예측 :  창조과학회 \n",
      "\n",
      "80\n",
      "질문 :  목재 선박은 강도상의 문제로 통상 길이 몇m가 한계인가?\n",
      "지문 :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "정답 :  100m\n",
      "예측 :  두배 이상 차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m \n",
      "\n",
      "81\n",
      "질문 :  노아의 방주 안정성을 실험하기 위한 연구가 있다고 주장하는 단체는?\n",
      "지문 :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "정답 :  창조과학회\n",
      "예측 :  창조과학회에서는 또한 노아의 방주가 \n",
      "\n",
      "83\n",
      "질문 :  목재로 만들어진 선박은 강도 상의 통상 길이 몇m가 한계인가?\n",
      "지문 :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "정답 :  100m\n",
      "예측 :  100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연구자는 지질학 석사학위 \n",
      "\n",
      "86\n",
      "질문 :  1868년 게이오 4년 4월 11일 신정부 군에게 양도되기로 한 반류마루를 기상 불량 등의 이유로 연기한 후 인도를 거부한 사람은 누구인가?\n",
      "지문 :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "정답 :  에노모토 다케아키\n",
      "예측 :  에노모토 다케아키 \n",
      "\n",
      "87\n",
      "질문 :  1868년 게이오 4년 8월 19일 자정 반류마루가 탈출한 해역은 어디인가?\n",
      "지문 :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "정답 :  시나가와\n",
      "예측 :  무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "질문 :  막부 해군이 정박하고 있던 시나가와 해역을 탈출한 시간은?\n",
      "지문 :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "정답 :  자정\n",
      "예측 :  8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Em \n",
      "\n",
      "90\n",
      "질문 :  1868년 당시 일본의 해군 부총재는?\n",
      "지문 :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "정답 :  에노모토 다케아키\n",
      "예측 :  에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부 \n",
      "\n",
      "94\n",
      "질문 :  반류마루가 미야코 만 해전에서 폭풍우를 만나 대기하고 있던 항구의 이름은 무엇인가?\n",
      "지문 :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "정답 :  하치노헤\n",
      "예측 :  마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 \n",
      "\n",
      "95\n",
      "질문 :  반류마루가 미야코 만 해전당시 폭풍우를 만나 요함과 헤어졌을 때에 만날 약속하여 하치노헤 항에서 대기한 날짜는 언제인가?\n",
      "지문 :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "정답 :  1869년 메이지 2년 3월 25일\n",
      "예측 :  1869년 메이지 2년 3월 25일 \n",
      "\n",
      "99\n",
      "질문 :  미야코 만 해전에서 아쓰오카 바키치 함장이 폭풍우를 만난 년도는?\n",
      "지문 :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "정답 :  1869년\n",
      "예측 :  1869년 메이지 2년 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_json = os.path.join(data_dir, \"korquad_dev.json\")\n",
    "\n",
    "with open(dev_json) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        question = vocab.decode_pieces(data['question'])\n",
    "        context = vocab.decode_pieces(data['context'])\n",
    "        answer = data['answer']\n",
    "        answer_predict = do_predict(model, question, context)\n",
    "        if answer in answer_predict:\n",
    "            print(i)\n",
    "            print(\"질문 : \", question)\n",
    "            print(\"지문 : \", context)\n",
    "            print(\"정답 : \", answer)\n",
    "            print(\"예측 : \", answer_predict, \"\\n\")\n",
    "        if 100 < i:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4. 학습 경과 시각화 비교분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-f749f88fc3df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 정확도 그래프 그리기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'darkred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# 축 이름\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2794\u001b[0m     return gca().plot(\n\u001b[1;32m   2795\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2796\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \"\"\"\n\u001b[1;32m   1664\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1666\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 폰트 설정\n",
    "#font_name = matplotlib.font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "matplotlib.rc('font', family='NanumBarunGothic')\n",
    "# 도화지 생성\n",
    "fig = plt.figure()\n",
    "# 정확도 그래프 그리기\n",
    "plt.plot(range(20), acc, label='Accuracy', color='darkred')\n",
    "# 축 이름\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('검증 정확도(%)')\n",
    "plt.title('epoch에 따른 검증 데이터에 대한 정확도 그래프')\n",
    "plt.grid(linestyle='--', color='lavender')\n",
    "# 그래프 표시\n",
    "plt.show()\n",
    "# 그래프 저장\n",
    "plt.savefig('korquad_tensorflow_acc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회고\n",
    "- 미세 조정을 하기 위해서 모델의 하이퍼 파라미터는 무엇이며 어떻게 접근하는지 방법을 모르겠음\n",
    "- 프리트레인된 모델을 불러와 학습하여 저장한뒤 이를 다시 불러와 이전과 같은 하이퍼파라미터 세팅에서 학습을 진행하였을때 모델의 성능 개선이 얼마나 이루어지는지 알고 싶었으나, 위와 같은 문제로 진행 할 수 없었음\n",
    "- 학습 경과 시각화 비교분석을 위한 결과값을 지닌 변수명을 알 수 없음\n",
    "- 해당 언어 모델에 대한 구조적인 이해가 아직도 명확하지 않음\n",
    "- 단순 코드를 따라 작성하는것으로는 학습의 진전이 없었음\n",
    "- 가장 단순한 언어 모델을 설계하는 과정부터 다시 학습할 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
